{"title":"How Predictable: Evaluating Song Lyrics with Language Models","markdown":{"yaml":{"title":"How Predictable: Evaluating Song Lyrics with Language Models","date":"2022-10-25","coverImage":"787349418_digital_art_oil_painting_impressinist_picture_of_a_microphone_making_music.png"},"headingText":"Language Models and Token Probabilities","containsRefs":false,"markdown":"\n\nI was briefly [nerd-sniped](https://xkcd.com/356/) this morning by the following tweet:\n\nhttps://twitter.com/unixpickle/status/1584761450979299329?s=20&t=TTgENBNO4pb7c1Ar2R7AJg\n\nCan we quantify how 'predictable' a set of lyrics are?\n\n\nA language model is a neural network trained to predict the next token in a sequence. Specifically, given an input sequence it outputs a probability for each token in its vocabulary. So, given the phrase \"Today is a nice \" the model outputs one value for every token, and we can look up the probability associated with the token for \"day\" - which will likely be fairly high (~0.5 in my tests).\n\nWe can look at the probabilities predicted for each successive word in a set of lyrics, and take the average as a measure of 'predictability'. Here's the full code I used:\n\n```\nimport torch\nfrom transformers import AutoModelForCausalLM\nfrom transformers import AutoTokenizer\ngpt2 = AutoModelForCausalLM.from_pretrained(\"gpt2\", return_dict_in_generate=True)\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n\nlyrics = \"\"\"\n    And my thoughts stay runnin', runnin' (Runnin')\n    The heartbreaks keep comin', comin' (Comin')\n    Oh, somebody tell me that I'll be okay\n\"\"\"\ninput_ids = tokenizer(lyrics, return_tensors=\"pt\").input_ids\nword_probs = []\nmin_length = 5 # How much do we give to start with\n\nfor i in range(min_length, len(input_ids[0])-1):\n    ids = input_ids[:,:i]\n    with torch.no_grad():\n        generated_outputs = gpt2.generate(ids[:,:-1], do_sample=True, output_scores=True,\n                                          max_new_tokens=1,\n                                          pad_token_id=tokenizer.eos_token_id)\n    scores = generated_outputs.scores[0]\n    probs = scores.softmax(-1)\n    word_probs.append(probs[0][ids[0][-1]])\n\ntorch.mean(torch.tensor(word_probs))\n```\n\nMy starting point was [this post](https://discuss.huggingface.co/t/generation-probabilities-how-to-compute-probabilities-of-output-scores-for-gpt2/3175) by Patrick Von Platen showing how to generate probabilities per token with GPT-2.\n\n## Results\n\nThe first test: 'Remind Me' by Megan Trainor. The mean probability given by the model for the next word given the lyrics up to that point: **0.58**!\n\nTrying a few other songs I could think of with less repetitive lyrics:\n\n- 'Levitate' (21 Pilots): **0.34**\n\n- 'Mom's Spaghetti' (MNM): **0.35**\n\n- The code example above: **0.45**\n\n- I'm Gonna Be (500 Miles)' (The Proclaimers): **0.59**\n\nThere is a caveat worth making which is that anything written before 2019 might be in the model's training data, and so it might 'know' the lyrics already making the measure less informative.\n\n## Historical Trends\n\nEDIT: Someone (me) didn't preview their data well enough, the lyrics I used for this were either badly scraped or very processed, so these scores won't compare well to the previous section and I need to re-do this with a proper dataset before we can say anything concrete about trends!\n\n![](https://datasciencecastnethome.files.wordpress.com/2022/10/download-2.png?w=826)\n\nPlotting the median estimated predictability per decade for a random sample of ~6k songs\n\nI downloaded a bunch of song lyrics via [this dataset](https://data.mendeley.com/datasets/3t9vbwxgr5/2) and sampled some from different years (1950 - 2019). For each, I estimated the predictability as described above. I found very little correlation (correlation coefficient 0.037 EDIT: 0.06 with a larger sample size) between predictability and year released, but there does seem to be a slight uptick in median predictability over time, especially going into the 2010s, which I'm sure will validate those grumbling about 'music these days'...\n\n## Conclusion\n\nThis was fun! Go play with the code and see if your least favourite song is actually as predictable as you think it is. Or perhaps run it over the top 100 current hits and see which is best. I should get back to work now, but I hope you've enjoyed this little diversion :)\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"2022-10-25-how-predictable-evaluating-song-lyrics-with-language-models.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"cosmo","title":"How Predictable: Evaluating Song Lyrics with Language Models","date":"2022-10-25","coverImage":"787349418_digital_art_oil_painting_impressinist_picture_of_a_microphone_making_music.png"},"extensions":{"book":{"multiFile":true}}}}}