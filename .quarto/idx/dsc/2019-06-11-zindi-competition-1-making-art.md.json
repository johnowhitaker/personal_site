{"title":"Zindi Competition 1 - Making Art!","markdown":{"yaml":{"title":"Zindi Competition 1 - Making Art!","date":"2019-06-11","categories":["blogs"]},"containsRefs":false,"markdown":"\n\nI'm going to try entering some Zindi competitions this week. First up is the 'AI Art' contest. I have many crazy plans, but my nascent tensorflow skills mean everything takes time. For now, let me present my first attempt:\n\n![](images/result1-1.png)\n\n'Bridge over Rainbow Water' - J Whitaker, 2019\n\nThis is made with a technique called Style Transfer. For more information and an easy way to try it out yourself, see the example on [Google Colab](https://research.google.com/seedbank/seed/neural_style_transfer_with_tfkeras). The general idea is to use a neural network to generate images that are similar to a 'content image' but that have the style of a separate 'style image'. The way the style difference is quantified is by using a network trained for image recognition - the early layers in these networks tend to measure style attributes.\n\nNow for the specifics of this piece:  \n\\- The general practice is to start from the content image, and slowly morph to an image that stylistically matches the style image. I turned this around, beginning with the style image and watching the structure slowly emerge.  \n\\- I tweaked the learning rate and other parameters, trying to maintain the curving, flowing nature of the style image even as the straight lines of the bridge come forward.  \n\\- Most styles are picked from famous artists. Since this is a co-creation with my laptop, the style image is a microscope image of my screen, which was itself displaying the microscope feed. The screen's sub-pixels are the source of the rainbow colours.\n\nSome attempts that didn't make the cut:\n\n- ![](images/out4.png)\n    \n- ![](images/out2-1.png)\n    \n- ![](images/screenshot-from-2019-06-11-09-29-40-1.png)\n    \n- ![](images/screenshot-from-2019-06-11-09-52-57.png)\n    \n- ![](images/screenshot-from-2019-06-11-09-52-49.png)\n    \n\nAs you might suspect, I've been playing with introducing distortion into the process. Just as we perceive a work in progress through the lens of our eyes (from different angles, with non-uniform lighting), I'd like the algorithm to only see a distorted view of it's output. This could be a blur or transform, but ultimately I'd like to try using a webcam and some wavy glass to create a means of perception for my co-artist.\n\nStay tuned for more attempts at music and art!\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"2019-06-11-zindi-competition-1-making-art.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"cosmo","title":"Zindi Competition 1 - Making Art!","date":"2019-06-11","categories":["blogs"]},"extensions":{"book":{"multiFile":true}}}}}