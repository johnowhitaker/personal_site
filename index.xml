<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>johnowhitaker.dev</title>
<link>https://johnowhitaker.dev/</link>
<atom:link href="https://johnowhitaker.dev/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.9.16</generator>
<lastBuildDate>Wed, 31 Dec 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>Isolating Flouresent Pseudomonas Bacteria from Houseplant Roots</title>
  <link>https://johnowhitaker.dev/posts/pseudomonas.html</link>
  <description><![CDATA[ 




<p><img src="https://johnowhitaker.dev/posts/images/pseud_agar_art.png" class="img-fluid"></p>
<p>I took a swab of the roots of one of our windowsill plants and streaked it out on some agar media to see what grew. After a day or two of growth, I shone a UV flashlight on the plate and saw that some colonies had a lovely blue glow! Likely candidate: Pseudomonas fluorescens, a common soil bacterium that secretes a blue-fluorescing siderophore called pyoverdine to scavenge iron from the environment.</p>
<p><img src="https://johnowhitaker.dev/posts/images/pseud1.png" class="img-fluid"></p>
<p>I tried to isolate the glowing bacteria by re-streaking to a fresh plate, although the first few tries brought along some other non-glowing bacteria as well:</p>
<p><img src="https://johnowhitaker.dev/posts/images/pseud2.png" class="img-fluid"></p>
<p>To confirm that this was what was happening, and get some more evidence for this being Pseudomonas, I did something called a gram stain where you smear some of thre bacgteria on a slide, stain it with a series of dyes, and then look at it under a microscope. This is what the result looks like:</p>
<p><img src="https://johnowhitaker.dev/posts/images/pseud3.png" class="img-fluid"></p>
<p>Pseudomonas are gram-negative rods, which are the smaller pink shapes in the image above. The larger black/purple shapes are gram-positive cocci, likely another harmless soil dweller. Another smear from the non-glowy part of the plate was ~all these larger dark blobs. It’s interesting that the larger bacteria get carried further when streaking, so most of the isolated colonies are just those, making it hard to pick out just the pseudomonas. Eventually I managed it though, and could start to have some fun.</p>
<p><img src="https://johnowhitaker.dev/posts/images/pseud4.png" class="img-fluid"></p>
<p>The glow comes from a chemical called pyoverdine. There are actually a bunch of variants made by different related species, I’d have to sequence the genome and do some analysis to figure out exactly which one I have. They all serve the same function - binding iron and making it available to the bacteria. This makes these beneficial to plants, since the pyoverdin is just secreted into the environment and can help the plant get iron too. There’s probably some mutualism going on here, with the plant providing nutrients to the bacteria in exchange for iron scavenging.</p>
<p>I put some rusty iron in vinegar + a little citric acid, to see if I could see the quenching happen. Here’s two vials, each with the same amount of pyoverdine (filtered to remove the bacteria themselves), with the left getting a few drops of water added and the right getting some of the iron solution:</p>
<p><img src="https://johnowhitaker.dev/posts/images/pseud5.png" class="img-fluid"></p>
<p>The effect is hard to capture in a photo, but the drops of iron result in an instant dark cloud effect, as the pyoverdine binds the iron and stops fluorescing. In daylight the resulting solution is yellow-green, and I think I saw some precipitate briefly form as well.</p>
<p>At some point I’ll make a video explaining this too, since glowy Rhizobacteria is a great hook to teach people about beneficial microbes and siderophores :) nSee you in the new year,</p>
<p>J</p>



 ]]></description>
  <category>bio</category>
  <guid>https://johnowhitaker.dev/posts/pseudomonas.html</guid>
  <pubDate>Wed, 31 Dec 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Measuring Caffeine Content with TLC at home</title>
  <link>https://johnowhitaker.dev/posts/caffeine.html</link>
  <description><![CDATA[ 




<p>Caffeine. Call it a drug, call it a vitamin. Many of us consume it daily - but how much? I’ve been a ~daily tea drinker a lot of my life (with periods of tapering off occasionally just to prove I’m not that big an addict) but strong coffee or yerba usually feels too strong for me. It’s bugged me for a while that there aren’t good options for figuring out how much you’re getting. When I steep my tea for seconds rather than minutes, what does that do to the dose? Are the green tea variants that claim ‘low caffeine’ really much less than regular black tea? How ‘decaf’ is decaf coffee? What about those kombuchas and boba teas and such people buy that don’t have any labelling for caffeine levels at all? Until this project, the cheapest option for testing at home was a $3k tester that cost &gt;$10 per test that was featured in a James Hoffman video [citation needed]. It’s based on differential pulse voltammetry, and looked pretty tricky to replicate at home. I’d looked into spectroscopic analysis, but you need pretty fancy setups to isolate out the caffeine signal from all the other stuff you might have dissolved in a beverage.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/WIyM2x7HtlY" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Then 3 weeks ago I was reading up on thin layer chromatography (TLC) for something else and wondered: would caffeine show up? Turns out the answer is yes! The TLC plages I got have a coating that flouresces under 250nm UV light (and I have a germicidal UV light for mutagenesis, post on that soon) but caffeine strongly absorbs that wavelength, and should show up as a dark smudge. I had some pure caffeine on hand too (for growing crystals, and to help mutagenesis, post soon too maybe) so I could make up some known concentrations for reference. The idea worked ‘in my head’ - I could see the blots in my minds eye. But of course, the real world would be messy, the concentrations would be way too low, it would never work the way I hoped right? Wrong! It totally worked!</p>
<section id="the-method" class="level2">
<h2 class="anchored" data-anchor-id="the-method">The Method</h2>
<p>Here’s the approach I settled on after a few tests.</p>
<p><img src="https://johnowhitaker.dev/posts/images/caffeine_calib.png" class="img-fluid"></p>
<ul>
<li>Mix up reference concentrations: 1000mg/L, 500mg/L, 250mg/L, 100mg/L, 50mg/L and 25mg/L</li>
<li>Spot on 7uL of the liquid to be tested near one end of a TLC plate. You can fit two comfortably on a plate - 3 is a squeeze, unless you spot much smaller quantities (you can spot, dry and re-spot to boost the signal, but it’s hard to be consistent).</li>
<li>Place in a few mm of Ethyl Acetate (EA) in a container (after letting the EA sit and evaporate a bit) and let it run up most of the plate.</li>
<li>Take out and dry flat.</li>
<li>Photograph while illuminated by a 250nm UVC bulb. (Wear safety goggles, UVC is not good for skin or eyes, mine lives in a box and is handled with care)</li>
</ul>
<p>This is already enough if all you care about is a rough measure of whether something is decaf, for example. But to make things a bit more quantitative, I loaded the image into solveit (an interactive jupyter-like environment) and grabbed the pixel values around each sample region, averaged and smoothed them, and plotted the results.</p>
<p><img src="https://johnowhitaker.dev/posts/images/caffeine_curves.png" class="img-fluid"></p>
<p>Plotting the delta between the peak and the baseline, we can get a measure that increases with concentration. Fitting a power law to the known concentrations gives us a way to estimate the concentration of the beverages. It’s pretty noisy at the low end though, and I was worried arbitrary choices like the size of the rect we draw around the blob might give different results. So, like a good scientist, I added error bars by re-running the analysis for a wide range of settings so we can estimate confidence intervals (“Monte Carlo sensitivity analysis” if you’re feeling fancy).</p>
<p><img src="https://johnowhitaker.dev/posts/images/caffeine_mc.png" class="img-fluid"></p>
<p>As expected, decaf coffee &lt; hojicha &lt; white tea &lt; black tea &lt;&lt; espresso*. The tea and yerba here are brewed my way, which is weak sauce. I tend to pour hot water (temp depending on tea) over the tea leaves or teabag, swish it around, and serve. Coming soon: results for brewing as the teas’ containers suggest.</p>
</section>
<section id="more-accuracy" class="level2">
<h2 class="anchored" data-anchor-id="more-accuracy">More accuracy</h2>
<p>The lowest two concentrations are hard to distinguish (indeed, I’m not sure if I got em switched to be honest) so all our teas are actually on the low end of a range this method can work for. There are two easy ways to fix this:</p>
<ul>
<li>Boil off 90% of the volume to get a stronger brew that will leave a clearer spot</li>
<li>Extract + concentrate the caffeine with EA. Some will be left in the tea, but we can do this to our known concentration samples too and get a repeatable method that way too.</li>
</ul>
<p>I’m going to try one or both of these soon - and will update this post when the results come in…</p>
<p>Update 1: shaking with EA then running that didn’t seem to give a useful signal</p>
</section>
<section id="stuff-that-mattered-didnt-work" class="level2">
<h2 class="anchored" data-anchor-id="stuff-that-mattered-didnt-work">Stuff that mattered / didn’t work</h2>
<ul>
<li>Acetone did move the caffeine, and with it I could actually see the spots under daylight while the plate was still wet with acetone. But it was smeary and hard to see - EA was much better.</li>
<li>Spotting samples on the plates one at a time, then running them a few days later, gave smeary messes. Run them soon after the spots dry. Once you’ve run the plate, you can keep it and compare it to others - so e.g.&nbsp;as long as I stick with the same volume of liquid and the same solvent I should be able to run future samples without needing to re-do the calibration ones</li>
<li>Running the plates in landscape mode lets you fit more samples on there, but makes it harder to get clean data out</li>
<li>Illumination changes can be calibrated out, but ideally you want even lighting from the UVC and a steady, focused pic from a decent camera. Make sure it isn’t over-exposed and that the spots are clearly visible.</li>
</ul>
</section>
<section id="re-running-on-an-energy-drink-with-a-known-concentration" class="level2">
<h2 class="anchored" data-anchor-id="re-running-on-an-energy-drink-with-a-known-concentration">Re-Running on an energy drink with a known concentration</h2>
<p>I did a run with “Melting Forest” MUSHROOM ENERGY, a curious beverage I spotted in our local New Seasons. Gratifyingly, the estimate (144.1mg +- 19.4mg) matches up perfectly with the stated dose on the can (150mg). Here’s the <a href="https://gist.github.com/johnowhitaker/c3bb0bca0c4c8f37324641c90e617e2c">code</a>. The video at the top walks through it.</p>
</section>
<section id="future-plans-conclusions" class="level2">
<h2 class="anchored" data-anchor-id="future-plans-conclusions">Future plans + conclusions</h2>
<p>Besides running this on a few more beverages and brew methods, I don’t really have grand plans for this. I hope this post + the accompanying video enable others who’ve wanted something like this to replicate the process, and who (like me) were frustrated by the lack of options for cheap testing. And more than that, I hope it inspires you to look for places in your own life where a bit of science could answer a question that you have :) Until next time,</p>
<p>J</p>
<p>PS: <a href="https://gist.github.com/johnowhitaker/43737282ef1da367aca7df9bf4a35522">code</a> from this first analysis, I’ll clean it up and share when I make the video (IF i make one, no promises)</p>
<p>PPS: coffee has other cool compounds that fluoresce under 360nm UV:</p>
<p><img src="https://johnowhitaker.dev/posts/images/caffeine_360nm.png" class="img-fluid"></p>
<p>In the plate pictured in this post:</p>
<p>Top row: standards (last two possibly switched?) Bottom row: Hojicha teabag, black teabag, yerba mate teabag brewed extra weak, Bai Mudan white tea (leaves), decaf espresso, regular espresso. TODO: measure espresso volume of my home cup.</p>
<p>PPPS: I pulled another shot of espresso for my cousin, turns out the cup I’ve been using is more like 90ml, which gives a dose of 121mg per cup not the 67 quoted in this post! (But the one I made may have been 70ml, and the extra smears might change things, so this measurement has extra high uncertainty)</p>
<p>PPPS: Featured on Hackaday! https://hackaday.com/2025/12/31/measuring-caffeine-content-at-home/</p>


</section>

 ]]></description>
  <category>mini-hw-projects</category>
  <guid>https://johnowhitaker.dev/posts/caffeine.html</guid>
  <pubDate>Mon, 22 Dec 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Tinkering with Tinker</title>
  <link>https://johnowhitaker.dev/misc/tinker.html</link>
  <description><![CDATA[ 




<section id="tinkering-with-tinker" class="level3">
<h3 class="anchored" data-anchor-id="tinkering-with-tinker">Tinkering with Tinker</h3>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/yId2PE5Qmqo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>My first impressions and initial few tests exploring Tinker, training an LLM to respond to all questions with ‘foo’ and then moving on to an RL example using a custom synthetic task and watching reward + accuracy go up and up :)</p>
<p><a href="https://share.solve.it.com/d/e52b8889b9d3571c1a67eda01aa540f4">Dialog</a>, <a href="https://gist.github.com/johnowhitaker/1d344202d525496e9664bab7c6196d05">Notebook version</a></p>
<p>Really impressed by this so far, expect more Tinker tinkering in the new year :)</p>


</section>

 ]]></description>
  <category>Video</category>
  <guid>https://johnowhitaker.dev/misc/tinker.html</guid>
  <pubDate>Wed, 17 Dec 2025 00:00:00 GMT</pubDate>
  <media:content url="https://johnowhitaker.dev/misc/thumbnails/tinker.png" medium="image" type="image/png" height="87" width="144"/>
</item>
<item>
  <title>Watching Bacteria NOT BE GREEN</title>
  <link>https://johnowhitaker.dev/posts/blygreen_p1.html</link>
  <description><![CDATA[ 




<p>I’ve been getting back into DIYBio, and the next step I wanted to try was making a custom plasmid. Casting about for ideas, I thought it would be neat to try for something that looks visibly green under natural light. You see, I’d bought a few <a href="https://atinygreencell.com/products/rainbow-chromoprotein-expression-plasmid-set">Rainbow chromoprotein sets</a> from Sebastian (<span class="citation" data-cites="atinygreencell">@atinygreencell</span>) to support his epic work, and while they are delightful, the green is basically yellow:</p>
<p><img src="https://johnowhitaker.dev/posts/images/rainbow2.jpg" class="img-fluid"></p>
<p>At least, until you look under UV or blue light - it’s a flourescent protein, so it glows bright green then (so do a few others):</p>
<p><img src="https://johnowhitaker.dev/posts/images/rainbow_uv.jpg" class="img-fluid"></p>
<p>After a deep dive into how Touracos get their green (TIL: copper) I decided to try a wacky idea.</p>
<section id="take-1-fusion" class="level2">
<h2 class="anchored" data-anchor-id="take-1-fusion">Take 1: Fusion</h2>
<p>Inspired by this <a href="https://thethoughtemporium.ca/products/electric-blue-1?srsltid=AfmBOooZZSCoBpI6RyCKpJSG7oRdLvRdTOQMlUCsEKbNAkohtPZlEHYI">electric blue plasmid</a> designed by Justin from the Thought Emporium, I figured I’d link together a yellow protein and a blue protein to get green. That’s how it works with paint, right? I dug around, found some candidate proteins, designed a construct, and had even started the order process for what I thought would be a very cool new protein:</p>
<p><img src="https://johnowhitaker.dev/posts/images/bly_alphafold.png" class="img-fluid"></p>
<p>I learned a ton about how the whole process works. It seems a lot of plasmid design involves copying strings of ATGACCGCGCTGACC… around, which I didn’t want to do, so I set about constructing it out of known pieces in a solveit notebook (an interactive coding environment). You can see the code <a href="https://github.com/johnowhitaker/BLY/blob/main/attempt_1_flawed/BLY_Designing_The_Plasmid.ipynb">here</a>. Some bits I learned:</p>
<ul>
<li>Keeping track of start and stop codons</li>
<li>Linking two proteins with a flexible linker</li>
<li>Back-translating from an amino acid sequence to DNA that should express it</li>
<li>The various other pieces of plasmid design - promoters, origins of replication, antibiotic resistance markers, terminators, Ribosome Binding Sites (RBS), etc.</li>
<li>Cloning restriction sites, including checking for accidental ones in the parts I wanted to use and making substitutions to remove them</li>
</ul>
<p>I’m pleased with the <a href="https://github.com/johnowhitaker/BLY/tree/main/attempt_1_flawed">result</a>, but as I waited for the DNA synthesis to start, a final LLM-assisted check caught a fatal flaw: aeBlue is a tetramer! That is, four monomers come together to make the final protein. Having yellow monomers hanging on could tangle up the process, leaving me with a non-functional mess. Oh no! Thankfully I managed to contact the kind folks at GenScript who were synthesizing the DNA for me, and they were able to cancel the order before it was made, and I frantically changed plan last minute and sent new DNA to them instead.</p>
</section>
<section id="sebs-work" class="level2">
<h2 class="anchored" data-anchor-id="sebs-work">Seb’s work</h2>
<p>More recently, chattingh to Sebastian, I mentioned this project and, lo and behold, he actually did just this way back in 2022!</p>
<p><img src="https://johnowhitaker.dev/posts/images/sebs_green.jpeg" class="img-fluid"></p>
<p>He thought it hadn’t worked, but eventually after putting it in a more productive strain and growing it out for a while, he got some visible green color. And he used aeBlue as his blue piece - so maybe mine would have worked after all! Alas. Still, having the chance to chat to someone experienced who had already tried this gave me some vital info for the rest of the project.</p>
</section>
<section id="my-revised-plasmid" class="level2">
<h2 class="anchored" data-anchor-id="my-revised-plasmid">My revised plasmid</h2>
<p>I somewhat frantically fell back on a plan B when I was rushing to get a new sequence to GenScript. The new plan: make the yellow and the blue separately, each with their own RBS and terminator, on the same plasmid. This way, they can fold up independently, hopefully avoiding the tetramer problem. And if the balance is off, this has the benefit that I can switch to a different promoter or RBS for one or the other to try to tune the expression levels. Here’s the new design (and the <a href="https://github.com/johnowhitaker/BLY/blob/main/BLYv2_green.ipynb">notebook</a> that I designed it in):</p>
<p><img src="https://github.com/johnowhitaker/BLY/blob/main/bly_green_pUC57-Kan%20Map.png?raw=true" class="img-fluid"></p>
<p>I switched to a weaker promoter than Seb’s designs, worrying about burdening the cells. This was probably a mistake given that it took him ages to see any expression - but then I didn’t know about his work then. I also gave up on worrying about cloning sites, and tried to keep it minimal. I did change the amino acid sequence of the fwYellow protein though, to add an easter egg I’ll reveal later ;)</p>
</section>
<section id="getting-it-in-cells" class="level2">
<h2 class="anchored" data-anchor-id="getting-it-in-cells">Getting it in cells</h2>
<p>I got the new plasmid in the mail, and an hour after it arrived the DNA was in some cells sitting replicating on a plate. The protocol I followed was essentially the same as that in my last post on <a href="https://johnowhitaker.dev/posts/bacterial_transformation.html">glowing bacteria</a> - with a few shortcuts and refiniements. I did have to whip up some sterile water to dilute the DNA - fortunately I have some syringe filters that did the job nicely. And now I have extra on hand in case I need it again in a hurry. The more you do, the more you learn and the moretricks you aquire! I’m feeling a lot more competent as I practice all the pieces of this puzzle.</p>
<p><img src="https://johnowhitaker.dev/posts/images/pBLY_no_color.jpg" class="img-fluid"></p>
<p>Alas, my transformed colonies grew out with ~no visible sign of color (well, with some imagination I think they’re sliiiightly darker than normal). I presume they took in the plasmid, since they’re living quite happily on kanamycin plates, but I guess the expression levels are too low to see anything. The strain I used is an old one, MM294, which isn’t optimized for protein expression. Seb had to switch to a BL21 derivative to get his to show up. So, I hold out hope.</p>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next steps</h2>
<p>I’m currrently ‘curing out’ some of Seb’s bacteria - streaking and re-streaking on plain plates in the hopes they ditch the current plasmid, leaving me plain BL21 ready to transform with my own plasmid. I actually tried a transformation a little impatiently this weekend, and was left with a lawn of cells - there were plenty that still had his kanamycin resistance, so I’ll need to be more patient curing it out :)</p>
<p><img src="https://johnowhitaker.dev/posts/images/colonies_w_pink.png" class="img-fluid"></p>
<p>You can see in the pic above some pink colonies lurking among the white ones, after I streaked out the first ‘white looking’ dot. I tested some candidate colonies on plain vs kan plates and saw no growth for one of them, but I guess I got unlucky when I then picked the cells for the transformation step. Lesson learned: wait for individual colonies to grow out, and test carefully :) Once I get a successful transformation into these BL21 cells, I’ll grow some on plates and some in liquid culture and see if we can see any green at all. Either way, it’s already been a great learning experience.</p>
<p>I’ll also say, it’s wild that an amateur can, with the help of some friends and AI, whip up a custom plasmid design, get it synthesized, and have it expressed in bacteria in a matter of weeks for a few hundred dollars. What a world! But also, a little scary. Mostly exciting though - I see the majority of uses for tech like this being positive, creative projects and hope more and more people get the joy of working with the living world. See you in part 2, hopefully ft some green!</p>
<p>PS: even if the proteins misfold or I fail from here, I’ll let you in on my secret. The amino acids at the end of the fwYellow sequence: VIKAVDLETYRGSGREEN. So, <em>technically</em>, I made GREEN! Uncountable copies in my plain-looking colonies, spelling out a small victory even in the midst of a setback. (A project for the future is running some PCR+gels to verify this small victory if we don’t get a more obvious one!)</p>
<p>Until next time,</p>
<p>J</p>
</section>
<section id="update" class="level1">
<h1>Update!</h1>
<p>I went to sterilize and throw out the plate with that wasn’t showing color, after it had been sitting at room temp for a few weeks. Lo and behold, rings of color - looks like at least aeBlue is expressing!!!</p>
<p><img src="https://johnowhitaker.dev/posts/images/bly_blue.png" class="img-fluid"></p>
<p>Cool that this sequence of DNA from an anemone (Actina equina) coding for a blue protein works in this random bacteria, albeit badly :D</p>


</section>

 ]]></description>
  <category>bio</category>
  <guid>https://johnowhitaker.dev/posts/blygreen_p1.html</guid>
  <pubDate>Sun, 14 Dec 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>AOC2025</title>
  <link>https://johnowhitaker.dev/misc/AOC2025.html</link>
  <description><![CDATA[ 




<p>Day 1: <a href="https://www.youtube.com/watch?v=-YRCgjcuAJ4">Here</a> is day 1. (<a href="https://share.solve.it.com/d/b004443523475274df5d756806394089">dialog</a>). I knew there was a nice floor-y way to do part two but between gabbling trying to verbalize my thought process and the inherent de-buff that being on video gives, I resorted to checking a range instead and immediately felt a little silly. Ah well - so it goes :)</p>
<p>Day 2: I recorded my solve attempt again (<a href="https://www.youtube.com/watch?v=a7HU3vxeCWI">here</a>, long and boring). I got bogged down in an optimization for part a that seemed like a good idea (and WAS a good idea on the sample data) but that knocked me off the rails a bit haha, code got worse and worse! I’d normally go on a walk, maybe if this happens again I’ll pause the recording rather than trying to keep typing. Still, ended up with basically the same solutions as everyone else here, albeit with a small trick for part 1.</p>
<p>Day 3: Much smoother, My <a href="https://share.solve.it.com/d/d59602c624d2ee1bcf68f4ee25915a18">dialog</a> and <a href="https://www.youtube.com/watch?v=Jd6QB5Xk8-Y">video</a>. Tea and slowing down for the win!</p>
<p>Day 4: My <a href="https://share.solve.it.com/d/9100d5e09acee8e3a0da36ef7ed8010f">dialog</a>, <a href="https://www.youtube.com/watch?v=Gn0Wcbd9GhQ">video</a> (both short today)</p>
<p>Day 5: Getting into territory where diagramming helps, thinking hard helps, and thinking about memory + speed starts to come up :slight_smile: My <a href="https://youtu.be/1ACIYLIgop4">video</a>. A little cheeky that ||the sample has ids sorted while the main input doesn’t! Good reason to look at your data :slight_smile: ||</p>
<p>Day 6, 7 and 8 got <a href="https://www.youtube.com/watch?v=FS34ADS5ZZQ">batched together</a> since I didn’t want to code on the weekend and had other business on Monday.</p>
<p>Day 9: Part 1 was easy, part 2 I fell for the temptation of trying to make the ‘grid’ for the full-size input - which turns out to be way too big to fit in memory! Solveit had an excellent suggestion to map coords to a much smaller space (since there are only ~500 so most rows + cols can be removed without changing the result) - as long as you then map back to OG coords for area this works and is reasonably fast. <a href="https://share.solve.it.com/d/c3642ada1b225996bb29f262d24719be">solution</a>. Viz’ing the grid in this compressed space shows the genius of the problem setters.</p>
<p><img src="https://johnowhitaker.dev/misc/thumbnails/grid.png" class="img-fluid"></p>
<p>Day 10. <a href="https://share.solve.it.com/d/3e001554b9c683a68d611f525560ba84">Dialog</a>. Part 2 I caved and just used the milp library. I liked my idea for part 1 to use a graph with a node per possible light state and then get the shortest path :)</p>
<p>Day 11. <a href="https://share.solve.it.com/d/8d7f092a3ad5095f582b8d8732b5a26f">Dialog</a>. More graph stuff. Was pleased to figure out I should look at the substeps for part 2, which then revealed a simplification we could make.</p>
<p>And Day 12! [Dialog]. A fun one to end on, and a good reminder to look at your data :D Here’s a <a href="https://www.youtube.com/watch?v=UanxRJL3rMU">video</a> covering days 10, 11 and 12. Thanks to Eric for setting all of these!</p>



 ]]></description>
  <category>misc</category>
  <guid>https://johnowhitaker.dev/misc/AOC2025.html</guid>
  <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Watching Bacteria GLOW</title>
  <link>https://johnowhitaker.dev/posts/bacterial_transformation.html</link>
  <description><![CDATA[ 




<p>This weekend I did my first successful bacterial transformation, inserting a plasmid that makes <em>E. coli</em> glow in the dark by expressing the ‘lux’ genes from bioluminescent marine bacteria. I’d <a href="https://johnowhitaker.dev/mini-hw-projects/2024-03-30-bio.html">had no luck</a> with a kit from the Odin (which I’ve since heard many bad reviewds about) - this time I went with an upgraded kit but also took advantage of more knowledge and tools aquired in the meantime, and it went extremely smoothly. This is sort of the ‘Hello World’ of synthetic biology, so naturally here’s my first agar art:</p>
<p><img src="https://johnowhitaker.dev/posts/images/bt_hw2.png" class="img-fluid"></p>
<p>This is all practice for when I get my own custom DNA made. How cool is it that this is possible! The glow is suprisongly bright - I had to cover the plate I put on my nightstand :) Here’s a plate ~12 hours after a transformation, you can see individual specks which are small colonies, each started from one individual cell that successfully took up the DNA and could thus survive on the antibiotic-containing agar:</p>
<p><img src="https://johnowhitaker.dev/posts/images/bt_new.png" class="img-fluid"></p>
<p>Here’s a plate that had some liquid on the surface which spread things around. It’s so bright you can read things like the dial on our coffee machine (photo on Google’s night sight mode so a little enhanced):</p>
<p><img src="https://johnowhitaker.dev/posts/images/bt_coffee.png" class="img-fluid"></p>
<p>It even grow nice and glowy on my home-made agar with no antibiotic, although I don’t think that would last (update: lost its glow a day later). The strain (MM294) is super safe and de-fanged, this is something they let high-schoolers do. All in all a great way to warm up for later projects :D Details below for the curious.</p>
<section id="the-details" class="level2">
<h2 class="anchored" data-anchor-id="the-details">The Details</h2>
<p>I’m working with <a href="https://www.carolina.com/gene-expression-advanced-topics/glow-in-the-dark-transformation-4-station-kit-with-perishables/211087P.pr">this kit</a> from Carolina Biological Supply Company, which contains enough materials for four students, but realistically can stretch to ~8 transformations, with easy ways to extend it further.</p>
<p>The kit comes with 4ml AMP <span class="citation" data-cites="10mg/mL">@10mg/mL</span>. They say to add it all to 200ml agar, but for the 8-person kit they give the same qty and say to add it all to 400ml agar. I decided to keep back 2ml (1ml + 2x 0.5ml aliquots) to freeze for later.</p>
<p>The process for pouring the plates I went with is:</p>
<ul>
<li>Wipe down surfaces and gloves with IPA</li>
<li>Melt the agar (bottle in boiling water with loose lid for a while, or microwave in short bursts. Make sure it is not cloudy and lumpy, and has all properly melted)</li>
<li>Let it cool to 55C. Work carefully by a flame</li>
<li>Pour 8 plates, and a few ml in a falcon tube for later stab of the starting e. coli</li>
<li>Add the remaining 2ml AMP (to half the bottle of agar, i.e.&nbsp;200ml -&gt; 100mg/L AMP which IIUC is standard) and swirl to mix</li>
<li>Pour 8 more plates</li>
<li>Invert, label, bag em up in ziplocs to store in the fridge, keeping one LB plate out to streak the starter</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://johnowhitaker.dev/posts/images/heat_shock.jpeg" class="img-fluid figure-img"></p>
<figcaption>Heat shocking with a 42C water bath</figcaption>
</figure>
</div>
<p>And here’s my protocol, cutting a few minor corners:</p>
<ul>
<li>Use a sterile pipette to add 250uL CaCl2 soln (50 mM) to a 15ml tube.</li>
<li>Place tube on ice for 10 minutes (along with the plasmid which I got out the fridge)</li>
<li>Transfer a few isolated colonies (goal is 2-5mm diameter from one or more) to the CaCl2, spinning the loop to dislodge the mass and then pipetting up and down a few times to mix (I used same pipette as measuring CaCl2 since still clean). Should look cloudy white, no clumps</li>
<li>Cells go right back on ice as soon as you’re done adding em and mixing.</li>
<li>Add 10uL of plasmid DNA. They say 1 loopful, I couldn’t get a bubble to form, I did 10uL with one of the janky pipettes I have around (luckily I’d practiced this, it’s ~2mm up the tubes I have give or take).</li>
<li>Incubate on ice for 5-10 minutes. Label the plate while waiting. I added 6 glass beads at this time too, for spreading the cells later.</li>
<li>HEAT SHOCK: move from ice directly into 42C water for 90 seconds, then back to ice for &gt;=1 minute. Gently agitate while in water bath.</li>
<li>Using fresh sterile pipette, transfer 250uL LB to tube, tap to mix, and leave at room temp for 5+ mins to recover and start expressing antibiotic resistance</li>
<li>pipette 100uL onto plate (I used same LB pipette) then spread by shaking the balls back and fourth</li>
<li>Let it rest a few minutes to absorb then dump out the balls (and disinfect them with IPA in my case)</li>
<li>Place plate upside down on 3D printer bed and ‘incubate at 30C for 24-36h or 36-60h at room temp’. (with 3D printer set to 35 plates are more like 28 but I don’t want to push too high so I left it at that).</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://johnowhitaker.dev/posts/images/incubate.jpeg" class="img-fluid figure-img"></p>
<figcaption>Incubating on a 3D printer bed</figcaption>
</figure>
</div>
<p>Tips - Add the plasmid gently - Work clean, don’t panic - Make sure the agar is fully melted (otherwise you get goopy lumps, don’t ask me how I know) - You can up your chances by adding more cells / more DNA. My first run I didn’t get many cells on the loop, the second go I used the wire innoculating loop and got a bigger colony or three that had had 12 hours more growth compared to the first run.</p>
<p>There are some great resources for learning more about this, my top rec is probably the <a href="https://www.youtube.com/@ThoughtEmporium">Thought Emporium YT channel</a>.</p>
<p>Anyway, stay tuned for more bio fun. I might have to set up a separate lab notebook to keep protocols and updates from polluting the blog post feed, organisation TBD :)</p>


</section>

 ]]></description>
  <category>bio</category>
  <guid>https://johnowhitaker.dev/posts/bacterial_transformation.html</guid>
  <pubDate>Sun, 30 Nov 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Watching Bacteria Grow</title>
  <link>https://johnowhitaker.dev/posts/watch_b_grow.html</link>
  <description><![CDATA[ 




<p>I’m getting back into microbiology, despite my <a href="https://johnowhitaker.dev/mini-hw-projects/2024-03-30-bio.html">misgivings from last time I dipped a toe into the field</a>. I’ll be attempting to insert a plasmid of my own design into bacteria - more on that coming soon! In the meantime, I’ve been practicing my sterile technique and messing about. In this post, while I wait for some cultures to grow for my first transformation attempt, I’ll introduce some of the stuff I’ve been playin with and show how I made a simple machine that logs optical density (OD) over time to plot bacterial growth curves.</p>
<section id="agar-plates-and-yummy-broth" class="level2">
<h2 class="anchored" data-anchor-id="agar-plates-and-yummy-broth">Agar Plates and Yummy Broth</h2>
<p>It can be fun to just make some agar plates and see what grows. I’ve been trying out just DIY-ing the broth. Recipe:</p>
<ul>
<li>250ml distilled water</li>
<li>1/2 tsp marmite</li>
<li>1/4 tsp ‘better than bouillon’</li>
<li>Add 4g agar agar if wanting solid media</li>
</ul>
<p>Dissolve the marmite and bouillon in hot water, then add to a glass bottle, add agar if using, and shake. Put the lid on loose, and boil for a while (shake if agar isn’t dissolving well). I left it simmering for a while on the stove then popped it into the insulated pot. Goal is to sterilize it all thoroughly.</p>
<p>You then wait for it to cool to ~55C before pouring into petri dishes. I also tried using little sauce tubs from the store - so far I haven’t had any contamination with them, I’m carefully opening the bag with gloves that have been sterilized with alcohol, working near a flame on a clean, sterile surface, and pouring then capping without much chance for stuff to float in.</p>
<p><img src="https://johnowhitaker.dev/posts/images/bio_lab_plates.png" class="img-fluid"></p>
<p>The first batch I made I used tap water, which here in Portland has some treatment that sticks around. Less grew on those than on the second batch where I used distilled water.</p>
<p>I did a test comparing some supplements a friend had that she <em>hoped</em> were sterile (they were not) with some probiotics I had that had one species alive and present (as the selling point) vs a control plate or two with nothing added. I also swabbed some of the flocs that I still have sitting around (they have algae growing there too now!) and got a much more diverse plate as a result, including a few pink colonies I’ve streaked out :) Probably a yeast like <a href="https://en.wikipedia.org/wiki/Rhodotorula">Rhodotorula</a> or something else…</p>
<p><img src="https://johnowhitaker.dev/posts/images/pink_colonies.png" class="img-fluid"></p>
<p>Under a scope they look like yeast (too big for bacteria) and stain with methylene blue. I might send them off for sequencing later.</p>
</section>
<section id="diy-optical-density-logger" class="level2">
<h2 class="anchored" data-anchor-id="diy-optical-density-logger">DIY Optical Density Logger</h2>
<p><img src="https://johnowhitaker.dev/posts/images/od_logger.png" class="img-fluid"></p>
<p>The idea with this machine is to log how much light gets through a tube with some broth and bacteria in it. As the bacteria grow, they block more light, so the amount of light that gets through decreases. By measuring this over time, we can plot a growth curve. This comes in useful later when, for example, you’re wanting to know when your bacteria are in the right phase of growth for transformation. On one side of the tube I have a white LED with a 220 ohm resistor. On the other, there’s a TEPT4400 phototransistor with a 10k ohm pull-down resistor. The phototransistor’s output is connected to an analog input on the raspberry pi pico which reads the voltage and sends it over serial. I store a reading (averaged across a bunch of samples) every 10 seconds. I hooked it up to my raspberry pi 5 so I could set it logging and leave it for many hours. The tube slots in and a cap goes down over it, with the gaps taped up, to keep ambient light from interfearing too much. Here’s what the curve looks like when I pop in some E. coli (strain MM294) into some marmite broth:</p>
<p><img src="https://johnowhitaker.dev/posts/images/bac_growth.png" class="img-fluid"></p>
<p>(Using <code>df['OD'] = -np.log10(df['volts'] / df['volts'].iloc[0])</code>). Since they’re in a small sealed vial, it doesn’t take long for things to slow. Also, I probably need to tweak Rsense and the setup in general to get cleaner, less noisy readings and better range. Still, cool huh!</p>
</section>
<section id="the-bigger-plan" class="level2">
<h2 class="anchored" data-anchor-id="the-bigger-plan">The bigger plan</h2>
<p>I’ve been reading textbooks and having fun learning about palsmid design. <a href="https://github.com/johnowhitaker/BLY">Here</a> is my current attempt at designing something fun - the resulting plasmids should show up in a week or so! As for the ‘larger plan’, I’m mostly just messing about and seeing where my interests take me. Here’s a rough attempt to map out the trajectory I’m picturing for now (I expect plenty more side quests will spawn along the way):</p>
<p>Base progression</p>
<ul>
<li>Make some plates (DONE)</li>
<li>Culture some things, practice streaking, colony picking, sterile technique (DONE)</li>
<li>Grow e. coli from carolina kit (DONE)</li>
<li>Transform with glowy plasmid, from kit (WIP)</li>
<li>Attempt a transform with <a href="https://github.com/johnowhitaker/BLY">my own plasmid</a></li>
<li>Agar art with my own transformed bug</li>
<li>Make new agar stabs of mine and sebs strains</li>
<li>Do a mini-prep</li>
<li>Run some gels (with a friend’s kit)</li>
<li>Follow interests from there</li>
<li>Teach - e.g.&nbsp;agar art kits, videos</li>
<li>Attempt a more complex genetic engineering project.</li>
<li>At some point: monitor turbidity in liquid culture for growth curves (This post!)</li>
<li>At some point, make a centrifuge + heat block type thing</li>
</ul>
<p>Pink side quest</p>
<ul>
<li>Swab flocs (DONE)</li>
<li>Pick and streak pink colonies (DONE)</li>
<li>Scrape a bunch up and extract pigment with acetone</li>
<li>Run chromatography (inc. on TLC plates - new kit/skill)</li>
<li>Agar art with them</li>
<li>Try some liquid culture maybe?</li>
<li>Test exposure to UV and how that affects pigment production.</li>
<li>Write up - would be a cool exploration! Especially if can be consistent extracting + photographing</li>
</ul>
<p>Read:</p>
<ul>
<li>Popsci (how life works (lame), song of the cell (better))</li>
<li>Bioprocess engineering (summaries only for later chapters),</li>
<li>Molecular biology of the cell (skim, research deeper for interesting bits). Ditto ‘Essential Cell Biology’, although I am enjoying giving some chapters more serious study.</li>
<li>Watch: Thought emporium, everymanbio, some lab technique videos.</li>
</ul>
<p>https://kevinhunter.opened.ca/ has great agar art info. TIL it <a href="https://www.smithsonianmag.com/science-nature/painting-with-penicillin-alexander-flemings-germ-art-1761496/">started with flemming</a></p>


</section>

 ]]></description>
  <category>mini-hw-projects</category>
  <category>bio</category>
  <guid>https://johnowhitaker.dev/posts/watch_b_grow.html</guid>
  <pubDate>Sat, 29 Nov 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Tab Clearning (Nov 2025)</title>
  <link>https://johnowhitaker.dev/misc/tab_clear_nov20_2025.html</link>
  <description><![CDATA[ 




<p>Clearing some recent tabs. I’m not sure how useful these posts are to anyone else, but they help me finally read + close things I’ve been meaning to get to.</p>
<p><img src="https://johnowhitaker.dev/misc/thumbnails/bacterial_cellulose.png" class="img-fluid"></p>
<ul>
<li>I’m getting into bio for the pretty colors :D Found this cool paper (https://www.cell.com/trends/biotechnology/fulltext/S0167-7799(25)00407-X) still need to read it properly but fun to see a recent example of things covered in the bioprocess engineering book I’m busy with.</li>
<li><a href="https://arxiv.org/abs/2511.07384">TEACHING PRETRAINED LANGUAGE MODELS TO THINK DEEPER WITH RETROFITTED RECURRENCE</a> - recurrent models seem to be having a moment, and I’m always a fan of starting from existing models to try stuff out.</li>
<li>LeJEPA paper</li>
</ul>
<p><img src="https://johnowhitaker.dev/misc/thumbnails/wlife.png" class="img-fluid"></p>
<ul>
<li><p><a href="https://writings.stephenwolfram.com/2025/11/whats-special-about-life-bulk-orchestration-and-the-rulial-ensemble-in-biology-and-beyond/">What’s Special about Life?</a> a nice Wolfram piece - the man makes good computation ‘model organisms’ for getting his point across!</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Eye_testing_using_speckle">Eye testing using laser speckle</a> TIL I am near sighted.</p></li>
<li><p><a href="https://archiveofourown.org/works/74161771">What Begets the End</a> (fiction/short story) lots of good ai-safety-adjacent writing recently</p></li>
<li><p><a href="https://www.suntory.com/sic/research/s_bluerose/story/">Blue roses</a> (they are not blue)</p></li>
<li><p>You should google ‘acoustic droplet ejection’ (ADE) / acoustic liquid handling — wild tech, e.g.&nbsp;the echo device can dispense liquids in 10nl droplets to mix different reagents together in tons of different wells for automated experiments at tiny scale. It sends an ultrasound pulse to sense the resevoir bottom, the meniscus and some liquid properties, then a strong pulse that ejects a droplet up and into an overturned well above. Crazy stuff.</p></li>
<li><p><a href="https://android-dreams.ai/">Android dreams</a> - an attempt at an AGI2027 style post for robotics. I find it hard to get much from these stories - robotics seems to be improving, the predicted developments often make sense, but guessing how things go in terms of quantities, dates, and further out scenarios is tricky.</p></li>
<li><p><a href="https://www.greaterwrong.com/posts/apHWSGDiydv3ivmg6/varieties-of-doom">Varieties of doom</a> sumary: ‘doom’ comes in many debatable flavours. (Seems like I have an AI safety skew in these links, which I don’t think reflects my browsing habit, only my ‘tabs I don’t actually read then close’ habit!)</p></li>
<li><p><a href="https://algaeresearchsupply.com/">Algae research supply</a> sell various cool things including a kit where you feed brine shrimp flourescent microplastics haha</p></li>
<li><p><a href="https://pyrofarms.com/">Pyrofarm</a> sell bioluminescent algae, extremely cool</p></li>
<li><p>I’ve been looking around at bio-related offerings, https://www.bio-world.com/, https://www.carolina.com/gene-expression-advanced-topics/glow-in-the-dark-transformation-kit/FAM_211086.pr?srsltid=AfmBOoqRoXZ9qhJH6bVUdAYbZov44Z08g6H6nLD0SktbJE5kCNdo7Wdg, https://amino.bio/products/engineer-it-kit, seem like cool kits are available and affordable. Also vectorbuilder.com, https://www.twistbioscience.com/products/genes, https://www.genscript.com/, seem like options for custom plasmids and addgene looks cool.</p></li>
</ul>



 ]]></description>
  <category>misc</category>
  <guid>https://johnowhitaker.dev/misc/tab_clear_nov20_2025.html</guid>
  <pubDate>Thu, 20 Nov 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reading Genomes thanks to Plasmidsaurus</title>
  <link>https://johnowhitaker.dev/posts/plasmidsaurus.html</link>
  <description><![CDATA[ 




<p>When I encounter an organism, I like to know what it is. My wifge once asked me, puzzled, why I have this drive. I stand by my first answer: I want to know if I can eat it! Naming something allows us to cross-reference information about that thing - from recipes to life histories :) Birds are easy - they sell books with pictures. Same goes for mammals, mushrooms, plants etc - at least the common ones. Bugs and spiders are harder - for some, you have to look at their naughty bits under a microscope (annoyance at this fact prompted me to put lots of working into making photo guides). When you get to bacteria, there’s really no hope in most cases… at least, that’s how I felt until recently! Turns out you can find out ‘what is this’ these days for a relatively modest sum of money, thanks to the magic of gene sequencing. In this post I’ll share my first experience answering one such question, then dig into a case study with data from a friendly internet biologist to show how far one can explore with some free tools (and a bit of specialist know-how).</p>
<section id="what-the-floc-is-that" class="level2">
<h2 class="anchored" data-anchor-id="what-the-floc-is-that">What the floc is that?</h2>
<p><img src="https://johnowhitaker.dev/posts/images/flocs.png" class="img-fluid"></p>
<p>Towards the end of my <a href="https://johnowhitaker.dev/posts/dwebench.html">duckweed experiments</a>, I noticed some things floating in some leftover stock solution of hydroponic nutrients I had made up. White, goopy blobs about a cm long. Was this some sort of weird precipitate? Some bacteria or yeast growing in there? A look under a microscope revealed a dense, tangled, squishy mess. A few tests ruled out mineral/chemical suspects, and after a bit of poking around my best answer was that these were probably biofilm flocs: mixed environmental microbes embedded in EPS (extracellular polysaccharide). That’s <em>an</em> answer, but how do we narrow it down to something more specific?</p>
<p>Enter <a href="https://plasmidsaurus.com/welcome">Plasmidsaurus</a>. They offer a number of services. In this case, I went for their “Microbiome 16S Amplification &amp; Sequencing with DNA Extraction” service. Following the guidance in the <a href="https://plasmidsaurus.com/sample-prep/microbiome#16S-extraction">sample prep</a> docs, I suspended ~0.1g of the goo in a product called ‘Zymo DNA shield’ (after a quick wash + spin down in 0.9% saline) and shipped the result (in a tube in a tube in a bag in a bag just to be safe) off to their lab in the nearby town of Eugene.</p>
<p><img src="https://johnowhitaker.dev/posts/images/floc_results.png" class="img-fluid"></p>
<p>The 16S gene is “highly conserved between different species of bacteria and archaea” and gets used to tell what somethig is without reading the whole genome - perfect for analysing environmental samples, gut bacteria etc. Plasmidsaurus will give you the raw reads, but they also do some processing to tell you some relative abundances of different species present (see above). In my case, it turns out these flocs are not a siongle species but instead a whole happy community of microbes! It’s fun to start researching and figuring out who might be doing what. Preliminary poking tells me this is not an unusual mix for a watery, nutrient-rich environment. Cool to see some <a href="https://x.com/allisonmegow/status/1983048944432353532">Methylobacterium present</a> - wonder how they’re getting food.</p>
<p>So, there you go. A much deeper answer to ‘what is that’, provided you’re willing to ship off a sample of goop and pay $60 + reagents and shipping. Is this as far as we can go though? No! <a href="https://x.com/johnowhitaker/status/1983004377318326522">Raw results here for the curous</a>. To dive even deeper, I’m going to switch to exploring the example that inspired me to go down this rabbit hole: the case of the mysterious triton X infiltrator.</p>
</section>
<section id="sebastians-mystery-bug" class="level2">
<h2 class="anchored" data-anchor-id="sebastians-mystery-bug">Sebastian’s Mystery Bug</h2>
<p><img src="https://johnowhitaker.dev/posts/images/tritonx.png" class="img-fluid"></p>
<p>Sebastian S. Cocioba🪄🌷 <a href="https://x.com/ATinyGreenCell"><span class="citation" data-cites="ATinyGreenCell">@ATinyGreenCell</span></a> is an amateur biologist who is continually doing amazing science stuff. He noticed a contaminant growing in his surfactant solution - a rough environment to be a bacteria! We sent it off for sequencing, but this time being a pro the approach was a little fancier than the one I showed in the previous section. For one thing, he guessed that his contaminant was mostly one organism, a bacterium, and so went with the bacteria genome sequencing with extraction option on the friendlty dino site. This was a bit of an informed gamble - the kind of shortcut one can take with experience.</p>
<p>He’s been sharing <a href="https://drive.google.com/drive/folders/1VRWijxODY-tEz_SEpgFz_OVNyNp6obG4">the data</a> and his explorations on X.</p>
<p>The main result from the run this time is a file with the reads: <code>K9P4V9_1_CONTAM-1.fastq</code>. In a <a href="https://gist.github.com/johnowhitaker/9c0b81329de6f26ace8c4b88a9f87dbf">solveit dialog</a> I loaded up the file and started poking at it. With some AI help, here’s how you might explore this type of data:</p>
<section id="load-the-data" class="level3">
<h3 class="anchored" data-anchor-id="load-the-data">Load the data</h3>
<p>FastQ files store each read in four lines. You can install the <code>biopython</code> library and read in the file like so:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> Bio <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SeqIO</span>
<span id="cb1-2">reads <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(SeqIO.parse(fn, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fastq"</span>))</span>
<span id="cb1-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Total reads: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(reads)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb1-4">reads[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> SeqRecord(seq<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Seq(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'CTGCATTGCGGGAATCGAGCTTTCGAGCGCAGCGAGAAGGTGATCTGCTGATTG...CGA'</span>), <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">id</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'427416c3-6c47-4f34-9889-f33a6ce52b84'</span>, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'427416c3-6c47-4f34-9889-f33a6ce52b84'</span>, description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'427416c3-6c47-4f34-9889-f33a6ce52b84 runid=0a805c02-f153-4c61-8572-df4a5e0b5651 ch=1767 start_time=2025-10-21T16:20:17.800804+00:00 flow_cell_id=PBG22075 basecall_gpu=NVIDIA_A100_80GB_PCIe protocol_group_id=251021LV_BACT sample_id=D barcode=barcode60 barcode_alias=barcode60 parent_read_id=427416c3-6c47-4f34-9889-f33a6ce52b84 basecall_model_version_id=dna_r10.4.1_e8.2_400bps_sup@v4.3.0'</span>, dbxrefs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[])</span></code></pre></div></div>
</section>
<section id="picking-some-reads-to-blast" class="level3">
<h3 class="anchored" data-anchor-id="picking-some-reads-to-blast">Picking some reads to BLAST</h3>
<p>I sorted the reads by length (<code>reads = sorted(reads, key=lambda r: len(r))</code>) and picked a few to look at (<code>chosen = [reads[100], reads[5000], reads[10000]]</code>). BLAST stands for “Basic Local Alignment Search Tool” - it looks for similarity between sequences, and when combined with a database of known sequences it’sa powerful tool for figuring out what on earth some specific string of DNA base pairs represents. You can download a giant database and run it locally, or submit one to NCBI’s BLAST like so:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> Bio.Blast <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> NCBIWWW, NCBIXML</span>
<span id="cb2-2">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NCBIWWW.qblast(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"blastn"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nt"</span>, chosen[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].seq)</span>
<span id="cb2-3">blast_record <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NCBIXML.read(result)</span></code></pre></div></div>
<p>The resulting record contains a list of <code>alignments</code>. These have a <code>title</code> (e.g.&nbsp;“Edaphobacter flagellatus strain HZ411 chromosome, complete genome”) and some info on how good the match is. In this case, we can see that the e-value (<code>alignment.hsps[0].expect</code>) is 0.0 (lower is better) with 536/543 (<code>{hsp.identities}/{hsp.align_length}</code>) bps matching. For all the reads I tried, the best match came from E. flagellatus, making this a strong candidate for who this particular contaminant is. (Sebastian agrees).</p>
</section>
<section id="reads---annotated-genome" class="level3">
<h3 class="anchored" data-anchor-id="reads---annotated-genome">Reads -&gt; Annotated Genome</h3>
<p>This bug turned out to be a little hard to crack (I guess it was living in a soap solution!) but the kind folks at Plasmidsaurus agreed to do a second run, resulting in more data. The way this works is that you aim to gen enough reads that you can stitch together the fragments with others that overlap until you have a complete circular genome. For a ‘good’ reconstruction you want about 30X coverage - i.e.&nbsp;each piece appears in at least 30 reads. When plasminsaurus advertises a given tier as being suitable for e.g.&nbsp;a 10 mega-base-pair genome, they mean they expect you’ll get this level of coverage across a genome that size. In this case, we ended up with enough reads that Sebastian was able to assemble a complete genome, but even if you didn’t (or if you only did the microbiome 16S example) and you wanted a full genome to play with, you can download one like so:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> Bio <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Entrez</span>
<span id="cb3-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set your email (NCBI requires this)</span></span>
<span id="cb3-3">Entrez.email <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"your.email@example.com"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Change this to your email</span></span>
<span id="cb3-4">handle <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Entrez.efetch(db<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nucleotide"</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">id</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CP073697.1"</span>, rettype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fasta"</span>, retmode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>)</span>
<span id="cb3-5">genome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> handle.read()</span>
<span id="cb3-6">handle.close()</span>
<span id="cb3-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"edaphobacter_flagellatus.fasta"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"w"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f: f.write(genome)</span></code></pre></div></div>
<p>Now what? The next step is to annotate this genome, which at present just looks like a string of 4.5 million letters. I signed up for an account, uploaded the genome we just downloaded, and got <a href="https://www.bv-brc.org/workspace/johnowhitaker@bvbrc/home/Edaphobacter%20flagellatus%20test_from_Entrez_CP073697.1">this</a> result via bv-brc. Again, if you’re doing this lots you can get tools to run this locally. See also, <a href="https://x.com/ATinyGreenCell/status/1981428984832278974">Sebastian doing this his way</a>. This annotation process tags specific sequences with features. Loading them in:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb4-2">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'~/Downloads/BVBRC_genome_feature.csv'</span>)</span>
<span id="cb4-3">functions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">', '</span>.join(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Product'</span>].unique())</span></code></pre></div></div>
<p>Taking a look at the annotated functions: <code>Transcriptional regulator, IclR family, hypothetical protein, Phage integrase, Amidohydrolase, Glutamyl-tRNA reductase (EC 1.2.1.70), Acidobacterial duplicated orphan permease (function unknown), Transcriptional regulator, PadR family, ...</code>. Lots and lots of “hypothetical protein”s here - this is what happens when you look at an understudied soil bacteria haha, shows how little we know! Since I’m a noob, I figured I’d pass the list to AI to see if there was anything interesting. In solveit, you can pass variables to claude like so: <code>Take a look at $functions - any stand out as potentially interesting / related to how it can live in tritonX?</code>. It was able to highlight specific bits, such as “CzcABC family efflux RND transporter”, explaining that “Efflux pumps actively pump toxic compounds out of the cell. RND (Resistance-Nodulation-Division) transporters are known for pumping out detergents and other membrane-disrupting compounds.”. Looking at the 31 efflux-related genes might not be a bad place to start when trying to figure out how this thing survives in the harsh environment it was growing in. (he says, like he knows what he’s talking about).</p>
<p>In a future post, I want to look further at how I might take an annotated protein (or pick one of the unknown ones) and look at it further - get the structure with alphafold 3, predict likely function, see which other species tend to have it and what they all do, etc etc. So many unknowns! But also so many good tools for digging in, and lots to learn :D</p>
</section>
<section id="a-masters-master-plan" class="level3">
<h3 class="anchored" data-anchor-id="a-masters-master-plan">A Master’s Master Plan</h3>
<p>It was really interesting to see how <span class="citation" data-cites="atinygreencell">@atinygreencell</span> went about playing with this. His interest goes beyond just figuring out what this is - instead, he has a process to turn it into something he can ‘play’ with! Once he has an assembled and annotated genome, his next steps are:</p>
<ul>
<li>Start to culture the bug. Growing it on agar and isolating colonies so that he can be sure no other bacteria and growing in with it, giving a clean slate to start with</li>
<li>Design some ‘primers’. These are small strands of DNA, matches for sequences in the target species. These will let him amplify <em>just</em> those sequences, giving a way to confirm that what he has growing is indeed E. flagellatus. (You amplify the sequences, if present, and then run a gel - where electric current separates DNA strands by size. If the primer had matches, you see a glowing band in the right place. I’m keen to try this some day!)</li>
<li>Develop a way to interface with this organism via plasmid transformation. Givig him the tools to knock out certain genes to see what they do, or add thigns. For example, he could see if knocking out a speciffic gene stops it being able to eat triton-X.</li>
<li>Now you have a new organism to experiment with - very cool, given how little we know about most wild bacteria and what they might be capable of doing!</li>
</ul>
</section>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>Anyway, I think it’s super cool that we can ship off samples to get sequenced for tens of dollars, and that you can buy the devices to do this yourself for a few thousand dollars. I think it’s wonderful that open databases and tools mean I could BLAST some reads, download a similar genome, annotate it and poke around to find some interesting genes from my laptop in a hotel room during PyTorchConf. I love that AI gives me a starting point for digging into questions that I have. I love that delightful and generous experts like Sebastian share their knowledge and augment my learning with their own deep expertise. And I love that there are so many things I still don’t know, and so many things humanity still doesn’t know! There’s a fat pile of textbooks sitting on my desk, and lots of open questions I have about these bacteria, so I suspect this won’t be the last post from me on this topic :) Until next time, cheers, J</p>
</section>
<section id="ps-folding-proteins" class="level2">
<h2 class="anchored" data-anchor-id="ps-folding-proteins">PS: Folding Proteins</h2>
<p><img src="https://johnowhitaker.dev/posts/images/folded_prot_comp.png" class="img-fluid"></p>
<p>I did a bit more messing around (vibe-research code <a href="https://gist.github.com/johnowhitaker/f4f1b88ffaa637476c62cb59ba9a2630">here</a>) and compared the wild-type genome to the reads of Seb’s bug. Found the genes common to both, and found 25 with differences ranging from single-base-pair or single-amino-acid up to pretty drastic changes. In this one, ‘Biopolymer transport protein ExbD/TolR’ it was cool to see a bunch of mutations but none in what I’m guessing is the ‘transmembrane region’ - i.e.&nbsp;the bit that is more hydrophobic, and important. I used alphafold 3’s free tier to fold the two variants and compare - although structures for floppy membrane proteins like this should be taken with a grain of salt.</p>
<p><a href="https://x.com/johnowhitaker/status/1989852477668413885">Tweet</a>: “I’m almost certainly making all sorts of mistakes, but I’m having lots of fun :) I found 876 annotated genes that occur in both genomes, of which 25 had changes ranging from a single base pair to big diffs like the prev tweet. Even a one-acid change like T-&gt;K (32) in the efflux transporter could be helping this bug live in the harsh environment of a flower designer’s surfactant solution? Anyway, fun stuff. So much to learn!” captures my mood :)</p>


</section>

 ]]></description>
  <category>misc</category>
  <category>bio</category>
  <guid>https://johnowhitaker.dev/posts/plasmidsaurus.html</guid>
  <pubDate>Thu, 06 Nov 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Kernel Crystals</title>
  <link>https://johnowhitaker.dev/misc/kernel_crystals.html</link>
  <description><![CDATA[ 




<p>Illustrating an idea I’ve been playing with - a kind of multi-scale convolutional cellular automata, that pushes how far one can go with random init.</p>
<p>Explanatory video: https://www.youtube.com/watch?v=Dt6Gm8AUj-o</p>
<p>NB: Code was an early morning rush job, index.html was a codex coded translation of my ramblings. For demo purposes only - one day perhaps I’ll have time to do some more didactic code for this and related fun</p>
<p>Demo: https://johnowhitaker.github.io/kernel_crystals/ Code: https://github.com/johnowhitaker/kernel_crystals</p>



 ]]></description>
  <category>Video</category>
  <guid>https://johnowhitaker.dev/misc/kernel_crystals.html</guid>
  <pubDate>Tue, 28 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://johnowhitaker.dev/misc/thumbnails/kc.png" medium="image" type="image/png" height="85" width="144"/>
</item>
<item>
  <title>Johno’s Lab - First Week of A New YouTube Channel</title>
  <link>https://johnowhitaker.dev/posts/johnoslab.html</link>
  <description><![CDATA[ 




<p>I’m taking a little time off, to get energized before our next course and because I was generally feeling a little tired out. It’s really important for me to have time to let my brain spin freely! I’ve done some good reading and resting and so on, but I do like to have a few bits of routine + structure even in a gap, and one experiment I thought I’d try this time is attempting to regularly post some short videos on old projects. Let me explain:</p>
<ul>
<li>I’m enjoying the low threshold of posting stuff here on my blog! But a lot of the bits and bobs I’ve been doing for fun (e.g.&nbsp;crystal timelapses) are well-suited to video.</li>
<li>I’ve been dreaming for ages of making long, high-quality videos on some of these ideas, but that’s a ton of time investment!</li>
<li>The hope is that a short video is enough to give ‘closure’ to some of the projects I’ve been stringing out, or to share unstructured updates, while still leaving open the possibility of a more casual, long-form video if there’s more I want to cram in.</li>
</ul>
<p><img src="https://johnowhitaker.dev/posts/images/shorts_thumbs.png" class="img-fluid"></p>
<p>As far as the format goes, I’m enjoying this so far! As a representative sample, I’ve “closed out” my duckweed experiments, with a catchy <a href="https://www.youtube.com/shorts/qcPMMdFlzqc">short</a> showing the motion I wanted to talk about, and a longer <a href="https://www.youtube.com/watch?v=4tjFAJ01_nM">background video</a> chatting about the backstory, why I was growing it, and how I think the motion arises (including a simulation of the phenomenon). I no longer have tubs of duckweed taking up one surface in my basement just waiting for me to finally get around to filming something. And I finally have a place to share the timelapse I took, the fun discovery of the motion, and the cool AI-for-science mini experiment that started it all off.</p>
<p><img src="https://johnowhitaker.dev/posts/images/shorts_stats.png" class="img-fluid"></p>
<p>The shorts medium is one I’m very unfamiliar with, and so that aspect has been interesting too. It seems like when I post a video, it gets a spike of views in the first ~hour and then dies off, with only a few continuing to get a trickle of views after that initial burst. Still, 10k views is a lot! I hadn’t thought through how many shorts people watch. The longer background videos are getting tens of views, more in line with what I expected for a new channel not marketing or anything.</p>
<p><img src="https://johnowhitaker.dev/posts/images/shorts_views.png" class="img-fluid"></p>
<p>One hope in posting these was that I’d inspire a bit of curiosity in people - maybe they’d take an experiment further than I did, or see the short and come explore the longer videos for more. Alas, I suspect that most shorts viewers are much closer to mindlessly scrolling, and I’m a little worried I’m just feeding that beast.</p>
<p>Indeed, setting up a fresh YT account (and a tiktok account, since I posted a few vids there too to test it out - with a few k views as a result) gave me a somewhat shocking view of what a shorts feed looks like. Selecting “STEM” in tiktok steered it towards some at least midly informative content, and my personal YT (tuned by decades of watching science+tech nerdery) was a little better, but it’s clear all of these things are optimizing for catchy + addictive first.</p>
<p>I’m still undecided if this is enough to put me off the medium completely - but I might shift purposefully away from anything too algo-friendly and stick to minimal editing of whatever I find interesting - moving lab notes rather than carefully scripted short videos. Also, a friend said I was ‘building a funnel’ and that made me stop for now, yuk.</p>
<p>Anyway, this excuse to go over a few old projects and start on a few new ones has reminded me of many good things. The ease with which we can whip up 3D printed bits, cobble together cheap hobby parts, and have AI help code up something neat is delightful! (a misc subset of recent prints below)</p>
<p><img src="https://johnowhitaker.dev/posts/images/3d_prints.png" class="img-fluid"></p>
<p>I also enjoyed taking a break from working, and leaning on AI a little more for the small bits of coding I did do - mostly simulation stuff that I could very easily + carefully describe, while letting the AI handle the boring scaffolding. As an example, I’m very plese with the shader inspired by the rheoscopic fluid stuff, and the bad apple side-quest <a href="https://www.reddit.com/poststats/1o88ujh">reddit post</a> I posted on reddit makes me happy - I’ve contributed to a long and silly tradition of people rendering that clip in weird ways, I’ve made something pleasing to look at + play with, and I could have creative charge without having to fix silly webgl errors.</p>
<p>Now that I’ve cleared a bit of my backlog, I’m going to dial back on the daily posting and switch to using this as I intended, as a more when-needed type place to dump clips. Subscribe if you’re interested :) And stay tuned for more posts here too - this isn’t going anywhere any time soon. :peace:</p>
<p>PS: I should link the channel! https://www.youtube.com/<span class="citation" data-cites="JohnosLab">@JohnosLab</span></p>



 ]]></description>
  <category>misc</category>
  <guid>https://johnowhitaker.dev/posts/johnoslab.html</guid>
  <pubDate>Fri, 17 Oct 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Biltong, Biofilm Flocs, Hyperspectral Glasses, Marangoni Photography, Poop Guns, Slide Scanning and Speedy Duckweed (Misc Updates)</title>
  <link>https://johnowhitaker.dev/misc/sept-2025-updates.html</link>
  <description><![CDATA[ 




<p>Updates on various small things that don’t justify their own posts just yet.</p>
<p><img src="https://johnowhitaker.dev/misc/thumbnails/miscu.jpg" class="img-fluid"></p>
<section id="biltong" class="level2">
<h2 class="anchored" data-anchor-id="biltong">Biltong</h2>
<p>On a recent hiking + bouldering + paddling trip, the topic of backpacking food came up with the sentiment ‘none of it is good’. Which reminded me of a South African staple I’ve been sorely missing here in the US: biltong. A dried meat, far superior to ‘jerky’. Turns out it’s easy to make! With the only downside being that while it’s drying I am continuously tempted by the alluring smell. Here’s my rough recipe:</p>
<ul>
<li>Slice up some steak</li>
<li>Marinate overnight in vinegar, worchesterchire sauce, salt, a little bit of brown sugar/molasses, and spices (pepper, ground corriander seeds, anything else that sounds fun) making sure all is covered</li>
<li>Hang to dry somewhere with a bit of air circulation. You’re aiming for e.g.&nbsp;20C with light air movement - too hot or too windy and the outside can harden too much. I use an air purifier to gently waft clean air over it.</li>
</ul>
<p>It’s done in around 3 days, tasty sliced or just gnawed on, tasty cut thinly and fried if you’re feeling decadent. The corriander and sweet vinegary saltiness is the taste of childhood treats for me.</p>
</section>
<section id="biofilm-flocs" class="level2">
<h2 class="anchored" data-anchor-id="biofilm-flocs">Biofilm flocs</h2>
<p>I noticed these white flakes in the bottom of a bottle of 5g/L hydrponic nutrient (MaxiGro) I had mixed up. They seem to be some kind of biofilm <a href="https://en.wikipedia.org/wiki/Floc_(biofilm)">floc</a>. No use for them that I can think of, but they are my pets now until I get around to throwing them out :shrug:</p>
</section>
<section id="hyperspectral-glasses" class="level2">
<h2 class="anchored" data-anchor-id="hyperspectral-glasses">Hyperspectral Glasses</h2>
<p>This is a fun side-quest! I learned that you can buy Dolby 3D glasses cheap on eBay which have different notch filters per eye, so they can each eye a different image. You can see the spectra and a representative photo through each eye on the right of the cover image. It’s a fun effect to walk around wearing these things. A lot of stuff looks ~no different, just mildly tinted some color or other. But anything where the color is strongly in a wavelength that hits one eye and not the other ‘shimmers’ in a way that looks like a video game quest marker for real life. Since these are often things like flowers, it’s a neat way to appreciate the world!</p>
<p>I set up a Raspberry Pi 5 with a battery pack and two identical camera modules to try and take some photographs/videos through both filters simultaneously, but the parallax made it not ideas. So I then tried fixing them over the color passthrough cameras on my Quest 3 VR headset and writing a shader that would show the edges/scene from one eye but blend the colors from both eyes in new combinations, to try to give you ‘hyperspectral’ vision. It kinda works but again alignment is tricky, and it’s such a pain accessing the passthrough cameras in Quest at the moment. It seems like they’re planning to give easier access at some point, I might just abandon this and wait for now. My final plan to show off these things to people who don’t have a pair is to capture a scene as a gaussiant splat 3 times - one with a normal camera, and then again with each of the two filters.</p>
<p>It’s so cool to me that some cheap pieces of glass can slice up the visible spectrum, and give us a chance to see more than we can with our measly 3 different cone cell types.</p>
</section>
<section id="marangoni-photography-and-high-speed-duckweek" class="level2">
<h2 class="anchored" data-anchor-id="marangoni-photography-and-high-speed-duckweek">Marangoni Photography and High-Speed Duckweek</h2>
<p>I had some duckweed soaking in IPA to extract the chlorophyll, and as I threw it in the sink I noticed some of them zooming around in circles. <a href="https://x.com/johnowhitaker/status/1952498896875479228">Here’s a video of this in action</a> from that first test (August 4). They look so alive! I think I can get them to do all sorts of tricks. I’ve been trying to figure out good ways to document the changing surface tension that drives the effect. So far I’ve got some <a href="https://x.com/johnowhitaker/status/1966670705199903135">trippy slo-mo</a> but not a technique I’m satisfied with yet.</p>
</section>
<section id="poop-gun" class="level2">
<h2 class="anchored" data-anchor-id="poop-gun">‘Poop gun’</h2>
<p>PSA: if you get <a href="https://www.amazon.com/dp/B0F8BHW5YN?ref=ppx_yo2ov_dt_b_fed_asin_title&amp;th=1">this drain unclogger</a> (as we did when a basement sink clogged, although it arrived after the crisis had passed) you are actually buying a small air-cannon, with a pump to fill a chamber with high-pressure air (it claims 100PSI, 60 is easy) and a quick-release trigger. We stuck a barrel on it, it shoots delightfully well :D Don’t tell our landlady about the dent in the drywall until we’ve patched it up! When a curious fly came sniffing around my biltong this gave a satisfying way to dissuade it.</p>
</section>
<section id="slide-scanning" class="level2">
<h2 class="anchored" data-anchor-id="slide-scanning">Slide Scanning</h2>
<p>I’m improved dramatically over <a href="https://johnowhitaker.dev/mini-hw-projects/scan_microscope.html">the previous slide scanning setup</a>, with a new plan objective, and a raspberry pi to control the 3D printer and take pictures with the camera module and a <a href="https://cad.onshape.com/documents/f0213fe7f0969bd58abd6976/w/b813f7b585f7d9ca72655df5/e/1cabd9e5c7051e7135563bc5?renderMode=0&amp;uiState=68d2c11a4943005b72ff2c56">3D printed adapter</a>. The microscope also got an upgraded plan objective. I’ve got these giant scan files with hundreds of images combined into a big mosaic, I’m working on ironing out the final kinks in the process and sharing the resulting images in a satosfying way. This will definitely get its own post at some point.</p>
</section>
<section id="other" class="level2">
<h2 class="anchored" data-anchor-id="other">Other</h2>
<p>I’ve been pretty busy with work, and pretty busy outside work with family stuff and outdoors activities. It feels like personal hobby stuff is getting a little neglected, relegated to tiny little things I can sneak in on a Sunday evening. I’ve got plans for more interesting stuff piling up - perhaps as we move into winter I’ll find more time to invest. In the meantime, I hope you, dear hypothetical reader, are enjoying the miscellaneous quick videos and mini-updates such as this :)</p>


</section>

 ]]></description>
  <category>misc</category>
  <guid>https://johnowhitaker.dev/misc/sept-2025-updates.html</guid>
  <pubDate>Sat, 20 Sep 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>If Anyone Builds It, Does Everyone Die?</title>
  <link>https://johnowhitaker.dev/essays/iabied.html</link>
  <description><![CDATA[ 




<p>Update 2025-09-23: I wrote out some quick thoughts right after reading the book, mostly to share with a few specific people. That original post is included below, but something about it feels lacking. There are so many takes in this space, many vastly incompatible with eachother. I’m adding a section at the end with reactions/takes from others I found interesting, and I encourage you to form your own opinions. ¯_(ツ)_/¯</p>
<section id="original-essay" class="level1">
<h1>Original Essay</h1>
<p>I’ve just finished IABIED. My father-in-law David also pre-ordered it, and his reaction is, predictably, a fair bit of hopelessness. Corporations are racing ahead chasing the money, that doesn’t seem like it’s going to stop. The book’s only recommendations are to shut down, with threat of nuclear bombs, any un-monitored GPU cluster with &gt;8 GPUs and ban new AI research. This seems unlikely to happen. What can we do? David’s youngest son is expecting, and talked yesterday about a 529 college savings plan. “What can I say to him? Like you can’t say this to a young father-to-be but there’s no way his kid is going to go to college!”. This essay is my attempt at some sense-making.</p>
<section id="a-quick-summary-of-the-book" class="level2">
<h2 class="anchored" data-anchor-id="a-quick-summary-of-the-book">A Quick Summary of the Book</h2>
<p>Part 1:</p>
<ul>
<li>Humans do well at intelligence (steering and predicting) which gives us immense power</li>
<li>LLMs and other AIs are ‘grown not crafted’</li>
<li>Training for an objective leads to acting like you ‘want’ something - e.g.&nbsp;chess AI ‘wants’ to protect its queen</li>
<li>Optimizing to an objective can lead to weird ‘wants’ - e.g.&nbsp;peacock feathers, non-reproductive sex in the case of evolution.</li>
<li>An ASI’s “wants” are likely to be extremely weird and not good for humans</li>
<li>We’d lose in a fight against ASI that wanted something different to us</li>
</ul>
<p>Part 2: One specific, fictional example, to help people visualize how a bad scenario could go down, without just waving hands at “some magic-like super-smart phenomenon we don’t understand hits us out of left field”. (review: There are other, better tales in this genre.)</p>
<p>Part 3: There are lots of pieces that make this problem very hard: we only get one try, takeoff might happen fast, this is a relatively new science (he compares it to alchemy), people are racing towards it anyway, believing it’s better they try first, people are afraid to be alarmist, it would take pretty drastic measures to stop it.</p>
<p>I think it’s well-written, and will reach lots of people with the ideas that Eliezer and co have been worried about for decades, ideas which are suddenly feeling a lot more pressing in light of the rapid AI advances of today. A lot of the steps in the argument are hard to argue with. They clearly took great care to communicate technical ideas like reasoning model training in a way that is mostly accessible to non-tech folks.</p>
</section>
<section id="so-are-we-doomed" class="level2">
<h2 class="anchored" data-anchor-id="so-are-we-doomed">So Are We Doomed?</h2>
<p>There are a few key claims in the book where I find room for more hope than the authors:</p>
<ol type="1">
<li>Interpretability: We don’t know anything about what is happening inside these networks</li>
<li>Alignment: The ‘wants’ that result from AI training will almost certainly be completely alien and extremely unlikely to be good for humans</li>
<li>Technology: We are building towards ASI of the kind he describes</li>
</ol>
<p>Let’s dig into each of those one by one</p>
</section>
<section id="what-are-they-thinking-interpretability" class="level2">
<h2 class="anchored" data-anchor-id="what-are-they-thinking-interpretability">What Are They Thinking? (Interpretability)</h2>
<p>Clearly we’re a ways from full understanding, but I think they undersell the interpretability field - we’re making great strides, and so far seem to be quite lucky in terms of how far even ‘simple’ techniques like linear probes can go in terms of understanding behaviours or finding worrying patterns. There are some deep laws of intelligence lurking - pockets of computational reducibility that we can exploit for understanding, as Wolfram might say.</p>
<p>As a bonus, reasoning models currently output their ‘chain of thought’ in ~English, and the labs are very aware that this is a fragile and beneficial state we shouldn’t throw away. There’s a <a href="https://arxiv.org/pdf/2507.11473">lot of agreement that this is worth preserving</a>, and a lot of work being done to ensure this remains a useful way to keep a window on these ‘thinking’ models to catch early signs of unwanted behaviour.</p>
<p>AI-assisted interpretability is also not nearly as doomed as they make out. The authors tend to treat intelligence as one singular, scalar value - a dumber model cannot hope to outwit a smarter model, and smarter models will be more dangerous. I disagree, and think (for example) we could build models focused on understanding what other models are ‘reasoning’ about, without needing to give the interpreter model any tools or agency.</p>
</section>
<section id="what-do-they-want-alignment" class="level2">
<h2 class="anchored" data-anchor-id="what-do-they-want-alignment">What Do They Want (Alignment)</h2>
<p>Now onto alignment, which the authors frame as this near-impossible task. After all, we can’t write down exactly what the ‘human values’ we want are, and even if we did, optimization towards those might instead lead to all sorts of warped and crazy actual ‘wants’, like a desire for smiles, which in turn might lead to engineering a smiling virus… If we were building these AIs from scratch, from some sort of self-assembling game-playing logic machines, which followed our specified rules like a malicious djinn following the letter of the wish in an old story, I’d agree we’re in trouble.</p>
<p>But we’re actually in a super lucky spot, thanks to how the tech is developing in practice. See, to get around the difficulty of carefully writing out the specific objective we want, it would be great if we could start the models out with some incredible, general distillation of human behaviours and values, some trove of interactions and information that gave them a more robust understanding of humans… something like the internet?</p>
<p>If you ask an LLM today “should I go camping in this park where there’s a wildfire warning”, the LLM will advise against it. This is not because the maker trained it to advise against hiking in wildfires, or because they carefully told it what to do in that situation. Instead, they trained it to advise against drinking bleach, and to recommend healthy habits, and to help out with programming and math problems. To get better at doing so, the LLM didn’t have to start from scratch. Instead, it built on the rich features and concepts it learnt during pre-training, including the convenient shortcut ideas that make all the specific examples more likely: be helpful, be good. These bleed into other cases, giving us AI’s that (in general) act ‘good’ in a huge number of situations.</p>
<p>This is great news! The model doesn’t need to learn what good is from a list of rules, it can build on the priors introduced by trillions of tokens of human-written text. This is a far nicer situation than we could have hoped for! And not one the authors envisioned when they were dreaming of uncaring evil optimizers back in the 2000s.</p>
<p>This isn’t to say that we get off easy. The trend is away from chatbots and more and more towards AI ‘agents’ that learn from reinforcement learning, not from human text. It’s possible that doing more and more RL will push the models further from the base they learn in pre-training, and could lead to weirder and more scary objectives - indeed, we already see a little bit of this with so-called “reward hacking”, where models are instructed to solve challenges fairly but learn over time that they can be rewarded for finding clever hacks to fool the tests they’re being trained on. This is an active area of research.</p>
<p>There’s also a worry here in terms of intentional mis-use. If a model understands good and bad, could someone train it to be bad intentionally? Alas, it seems so. In fact, training it to be bad in one area (e.g.&nbsp;writing insecure, hackable code) can <a href="https://arxiv.org/abs/2502.17424">lead to a model that also acts racist and mean</a>! It might be almost as simple as flipping a plus sign to a minus sign deep in the model internals - something that will get more worrying as capabilities continue to advance.</p>
</section>
<section id="what-are-we-building-technology-now" class="level2">
<h2 class="anchored" data-anchor-id="what-are-we-building-technology-now">What Are We Building? (Technology now)</h2>
<p>Building on the past two sections, the situation at present is nicer than the book would have us believe. Current systems are trained on human data, and have a more robust understanding of ‘helpful’, ‘honest’ and ‘harmless’ than early theorists could have hoped for.</p>
<p>Furthermore, they’re extremely incentivised to keep getting better in this regard. AI companies make money if their AI behaves well! Training involves taking in text and producing more text, and deployment looks the same. While some models have some ‘situational awareness’ to know when they’re deployed, we can still:</p>
<ul>
<li>inspect the text they’re producing, including with other ‘monitor’ models that can detect early signs of bad behaviour</li>
<li>pause the process at any time (the book uses lots of rhetoric about 10000X faster thinking to show danger, but current models have no way to know what speed they’re going or if we’re carefully inspecting their inner activations)</li>
<li>catch signs of unintended behaviour in testing or early deployment, and roll back to earlier models if these are too bad (e.g.&nbsp;Grok’s “MechaHitler” arc was rapidly cut short)</li>
</ul>
<p>We’re a far cry from the picture in the book’s Part 2, where an AI entity schemes to itself for tens of thousands of GPU hours in inscrutable self-invented language, and then plans and executes it’s evil plan over many instances of itself over many months.</p>
<p>People are actively working on safety in many different ways, and again labs have incentives to keep building systems that reliably do what we want. There’s a lot of pressure against anything that develops ‘misaligned’ wants.</p>
</section>
<section id="what-will-we-build-next" class="level2">
<h2 class="anchored" data-anchor-id="what-will-we-build-next">What Will We Build Next</h2>
<p>AI is being built by people, in corporations. Their motivations vary, but most are genuinely pursuing ways to add value: helping people do more, solving scientific challenges, creating more and more value for other corporations and society.</p>
<p>In one sense, there’s a single direction we go from here: better. AI models will continue to do better and better on various objectives we set. But when you look closer, there are different paths we could take, determined by economic incentives and the choices of those leading the charge.</p>
<p>One dimension I wish we could tweak is the move towards more and more ‘agentic’ AI. This is something we care a lot about at my company - AI as human augmentation, with human driving, is an immensely useful and empowering tool. But too many view the real use as human replacement - a virtual employee you can delegate work to. Besides de-valuing humans, this is a direction that doesn’t help the safety side! Yoshua Bengio prominently believes that pushing for non-agentic AI is key to maintaining safety as we push capabilities forward, and I agree.</p>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>I am much more hopeful than the authors that we will be able to keep solving problems and moving forward, building AI that helps humans do more, pushing back the frontiers of knowledge without destroying the world.</p>
<p>It’s worth thinking carefully about the risks. It’s good that people are thinking about policy that could slow down the chance of bad outcomes. I hope that concensus shifts away from the mad rush into agentic human replacements, and that we collectively spend some time dreaming about what types of future we’d like to usher in. I hope the ‘race’ dynamic doesn’t cause megacorps to throw out some of their ideals.</p>
<p>I can’t claim certainty. But I don’t think everyone is going to die. Especially if we proceed carefully and push towards human-centered AI tools, and away from unchecked agency.</p>
<p>I have no idea what the future looks like. It probably involves a lot of change. But I hope this little brain-dump helps you keep a spark of hope that, just maybe, that kiddo will have a cooler college experience than any of us old cynics could dream of :)</p>
<section id="ps-other-worries" class="level3">
<h3 class="anchored" data-anchor-id="ps-other-worries">PS: Other Worries</h3>
<p>This post focused on ‘ASI’ specifically, the focus of IABIED. There are other reasons to be concerned, some that come up if we do build powerful AI and some that stem from attempts to avoid that. The book mostly ignores these - fair, considering that if you believe the books titular conclusion then all of these are, by comparison, small fry. Still, including them here for completeness and reference until I decide to edit this out for brevity :)</p>
<p>If we try not to build it:</p>
<ul>
<li><p>Authoritarian surveillance state: The book advocates for extreme oversight measures, to ensure that nobody builds ASI. Implementing these would require extreme surveilance and power in the hands of the governments, which could lead to it’s own bad outcomes.</p></li>
<li><p>Concentration of Power: Making (incredibly valuable and useful) AI something that only a few have direct control over is a recipe for concentration of power and wealth, leading to bad outcomes of a different kind</p></li>
</ul>
<p>If we build it safely:</p>
<ul>
<li><p>Misuse: someone might still be able to transform safe, powerful AI into something harmful and unsafe, e.g.&nbsp;by re-training it to agentically pursue damaging cyberattacks or using it to design bioweapons</p></li>
<li><p>Gradual disempowerment: if we become too dependant on AI, we might slowly lose our skills and bargaining power, leaving the bulk of the population with less hold on how they are treated and what their lives look like going forward.</p></li>
<li><p>Misaligned incentives between corporations and humans, as is already happening with addictive scrolling content like tiktok, and which could get far worse as companies push ‘relational’ AI further while optimizing for engagement or profit.</p></li>
</ul>
</section>
</section>
<section id="other-takes" class="level2">
<h2 class="anchored" data-anchor-id="other-takes">Other Takes</h2>
<p>I have been keeping an eye out for other takes on this book. Here are some:</p>
<p>Jeremy Howard: Calling for extreme measures to suppress research will concentrate power in the hands of a few is a very bad idea. <a href="https://x.com/jeremyphoward/status/1969541019437056362">Who is suggesting this</a>? <a href="https://x.com/jeremyphoward/status/1968887354413748270">This could lock in the status quo of power</a>. See also <a href="https://www.fast.ai/posts/2023-11-07-dislightenment.html">AI Safety and the Age of Dislightenment</a>.</p>
<p><a href="https://x.com/mimi10v3/status/1968731768212881707">A summary of the book on Twitter that seems accurate and a good way to get the jist without reading it</a>, posted after their <a href="https://x.com/mimi10v3/status/1967839789375426876">original tweet</a> containing just the first few words of each chapter (usually part of a parable) was interpreted as a hilarious diss on Yud</p>
<p><a href="https://www.vox.com/future-perfect/461680/if-anyone-builds-it-yudkowsky-soares-ai-risk">A decent vox article</a> on the book, capturing the conflicting ideals and that this is a clash of worldviews.</p>
<p><a href="https://x.com/jd_pressman/status/1968847166316625989">JDP’s review</a></p>
<p><a href="https://x.com/willmacaskill/status/1968759901620146427">William MacAskill’s review</a> - who found the book disappointing</p>
<p><a href="https://x.com/teortaxesTex/status/1968856896107888656">Teortaxes’ review draft</a> - a critical take that this book is counterproductive and will damage reasonable AI risk discourse</p>
<p>Lots of other immediate dismissals, lots of other ‘this is the most important book ever’ takes. Is it good that this will get everyone talking, or bad that it will get everyone taking based on flawed arguments, or good because we’re all going to have to keep repeating the title which states the premise which might skew public policy, or bad because actually we’re not on track to build ASI at all and this might make it harder to make nice medical AI and stuff, or good because… like I said - I encourage you to form your own opinions ¯_(ツ)_/¯</p>


</section>
</section>

 ]]></description>
  <category>essays</category>
  <guid>https://johnowhitaker.dev/essays/iabied.html</guid>
  <pubDate>Wed, 17 Sep 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>What Is Solveit?</title>
  <link>https://johnowhitaker.dev/posts/solveit.html</link>
  <description><![CDATA[ 




<p>At the end of last year, we ran a small course titled “How To Solve It With Code”. We closed signups after a day, and 1000 keen beans joined us for a 10-week deep dive into our general approach to solveing problems. It was taught via the vehicle of the ‘Advent of Code’ programming challenges and run in a new, purpose-built tool called solveit. As the course progressed, we had lots of fun going far beyond the original scope, exploring web development (with FastHTML), AI, business (with Eric Reis as a special guest), writing and more. And the solveit tool became an extremely useful test-bed for ideas around AI-assisted coding, learning and exploration. In the year since, we’ve continued to refine and expand both the process and the tools built in service of said process, and are ramping up for another cohort to share these developments with a wider audience. So, I figure it’s high time I attempt to write down my own version of what ‘the solveit method’ is… :)</p>
<section id="inspiration-from-polya" class="level2">
<h2 class="anchored" data-anchor-id="inspiration-from-polya">Inspiration from Polya</h2>
<p>George Polya was a Hungarian mathematician who wrote the influential book “How to Solve It” in 1945. In it, he shares his philosophies on education (focus on acive learning,heuristic thinking and careful questioning to guide stodents towards discovering answers for themselves) and outlines a four-step problem-solving framework:</p>
<ol type="1">
<li>Understand the Problem: identify what you’re being asked to do; restate the problem</li>
<li>Devise a Plan: draw on similar problems; break down into manageable parts; consider working backward; simplify the problem</li>
<li>Carry Out the Plan: verify each step</li>
<li>Look Back and Reflect: consider alternatives; extract lessons learned</li>
</ol>
<p>He was focused on mathematics, but as Jeremy and I tried to codify our approach to solveing problems with code, we realized that these ideas translate far beyond maths!</p>
</section>
<section id="application-to-coding-iterative-exploratory-coding-in-notebook-like-environments." class="level2">
<h2 class="anchored" data-anchor-id="application-to-coding-iterative-exploratory-coding-in-notebook-like-environments.">Application to Coding: iterative, exploratory coding in notebook-like environments.</h2>
<p>Let’s consider a quick example. For 2024’s Advent of Code, Day 1’s solution involves comparing two lists, sorted by value (there’s a whole backstory involving elves, which you can <a href="https://adventofcode.com/2024/day/1">read if you like</a>). Let’s imagine we’ve considered the problem, and are now focused on a small sub-task: extracting the first (sorted) list. We start with the sample data provided:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3 &nbsp; 4</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">4 &nbsp; 3</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">2 &nbsp; 5</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">1 &nbsp; 3</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">3 &nbsp; 9</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">3 &nbsp; 3'</span></span></code></pre></div></div>
<p>Our plan might be:</p>
<ul>
<li>Split into a list of lines</li>
<li>Grab the first number from each line</li>
<li>Sort</li>
</ul>
<p>You could likely write this function in one go. Indeed, if you typed <code># Get a sorted list of the first number from each line</code> your AI auto-complete could likely do the rest. But we’re trying to build a discipline that will serve us on harder tasks that neither humans nor AI can one-shot. So, after thinking through the plan, we begin working on individual steps. We aim to write no more than a few lines of code at a time, with each piece giving some useful output that you can use to <strong>verify</strong> that you’re on the right track:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">lines <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.splitlines()</span>
<span id="cb2-2">lines</span>
<span id="cb2-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3 &nbsp; 4'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'4 &nbsp; 3'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2 &nbsp; 5'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'1 &nbsp; 3'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3 &nbsp; 9'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3 &nbsp; 3'</span>]</span></code></pre></div></div>
<p>Now we build up a list comprehension to get the first elements. We might start with <code>[o for o in lines]</code> and then add bits one at a time, inspecting the output, building up to:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">l1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(o.split()[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> o <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> lines]</span>
<span id="cb3-2">l1</span>
<span id="cb3-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]</span></code></pre></div></div>
<p>Now sorting:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sorted</span>(l1)</span>
<span id="cb4-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]</span></code></pre></div></div>
<p>Now that we’ve run all the pieces individually, and checked that the outputs are what we’d expect, we can stack them together into a function:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_list(x):</span>
<span id="cb5-2">&nbsp; &nbsp; lines <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.splitlines()</span>
<span id="cb5-3">&nbsp; &nbsp; l1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(o.split()[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> o <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> lines]</span>
<span id="cb5-4">&nbsp; &nbsp; <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sorted</span>(l1)</span>
<span id="cb5-5">get_list(x)</span>
<span id="cb5-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]</span></code></pre></div></div>
<p>At this point, you’d reflect on the solution, think back to the larger plan, perhaps ask yourself (or ask AI - more on that later) if there are better ways you could do it. You may be thinking that this is far too much work for <code>sorted(int(line.split()[0]) for line in x.splitlines())</code> - as your skill increases you can tailor the level of granularity, but the idea remains the same: working on small pieces of code, checking the outputs, only combining them into larger functions once you’ve tried them individually, and constantly reflecting back on the larger goal.</p>
</section>
<section id="the-power-of-fast-feedback-loops" class="level2">
<h2 class="anchored" data-anchor-id="the-power-of-fast-feedback-loops">The Power of Fast Feedback Loops</h2>
<p>The superpower that this kind of live, iterative coding gives you is near-instant feedback loops. You’re not building your giant app, waiting for the code to upload, clicking through to a website and then checking a debug console for errors - you’re inspecting the output of a chunk of code and seeing if it matches what you expected. It’s still possible to make mistakes and miss edge cases, but it is a LOT easier to catch most mistakes early when you code in this way.</p>
<p>This idea of setting things up so that you get feedback as soon as possible pops up again and again. Our cofounder Eric Ries talks about this in his book ‘The Lean Startup’, where getting feedback from customers is valuable for quick iteration on product or business ideas. Kaggle pros talk about the importance of fast evals - if you can test an idea in 5 minutes, you can try a lot more ideas than you could if each experiment requires 12 hours of model training.</p>
<p>This is one reason many people like ‘Test Driven Development’ - where carefully written tests check for expected behaviour. The answer.ai style of notebook-driven development just uses a mix of “proper” tests (e.g.&nbsp;asserts thoughout the notebooks that check things formally) and the human-based sanity checks based on inspecting outputs as we go.</p>
</section>
<section id="ai-shared-context-is-key" class="level2">
<h2 class="anchored" data-anchor-id="ai-shared-context-is-key">AI: Shared Context is Key</h2>
<p>So far so good - sounds like we’re describing the style of exploratory/literate programming taught in the fast.ai course, and used with tools like NBDev. Aren’t we in a new era though? Where is the AI?!</p>
<p>Well, it turns out that by building code in this way, with planning, notes and tests mixed in with the source code, you’re also building the perfect context for an AI to help with the code too. Solveit can see everything you can see. This means great contextual auto-complete, and solid answers to any questions you have.</p>
<p>You can also feed it additional context by referencing specific variables, or having it use its built-in search and URL-reading tools. And any python function becomes a tool that you can ask solveit to use, making it easy to give it everything it needs to fetch more context or take “agentic” actions to give better responses.</p>
<p>TODO: note on shell-sage?</p>
</section>
<section id="ai-dialog-engineering-keeps-context-useful" class="level2">
<h2 class="anchored" data-anchor-id="ai-dialog-engineering-keeps-context-useful">AI: Dialog Engineering Keeps Context Useful</h2>
<p>One issue with current chat-based models is that once they go off the rails, it’s hard to get back on track. The model is now modelling a language sequence that involves the AI making mistakes - and more mistakes are likely to follow! Because solveit dialogs are fluid and editable, it’s much easier to go back and edit/remove dead ends or unrelated explorations. You can even edit past AI responses, to steer it into the kinds of behaviour you’d prefer. Combine this with the ability to easily hide messages from the AI or to pin messages to keep them in context even as the dialog grows beyond the context window and starts to be truncated, and you have a recipe for continued AI helpfullness as time goes on.</p>
<p>Of course, this is all useful for humans too! The discipline of keeping things tidy, using (collapsible) headings to organise sections, writing notes on what you’re doing or aiming for, and even past questions+answers with the AI all make it a pleasure to pick back up old work.</p>
</section>
<section id="ai-collaboration-not-replacement" class="level2">
<h2 class="anchored" data-anchor-id="ai-collaboration-not-replacement">AI: Collaboration not Replacement</h2>
<p>One thing is still (intentionally) hard in solveit though, and that is getting the AI to actually write all your code in a hands-off way. We’ve made various choices to gently push towards the human remaining in control:</p>
<ul>
<li>Defaults to code inputs</li>
<li>AI outputs code in fenced blocks, but these are not added to your code or run until you choose to do so. There are shortcuts to add them, but this extra sterp encourages you to read + refactor before mindlessly running</li>
<li>In ‘Learning’ mode especially, the AI will gently guide you to writing small steps rather than providing a big chunk of code, unless you really specifically ask it to do so.</li>
<li>In ‘Learning’ mode, the AI ‘ghost text’ auto-complete suggestions don’t show unlesss you trigger them with a keyboard shortcut.</li>
</ul>
<p>Even the choice to have the editor be fairly small and down at the bottom emphasizes that this is a REPL/dialog, optimised for building small, understandable pieces.</p>
</section>
<section id="learning-trajectory-getting-more-powerful" class="level2">
<h2 class="anchored" data-anchor-id="learning-trajectory-getting-more-powerful">Learning Trajectory (Getting More Powerful)</h2>
<p>This brings us to another foundational piece of the solveit approach: a learning ,mindset. It’s great that we can ask AI to fill in the gaps of our knowledge, or to save some time with fiddly pieces like matplotlib plots or library-specific boilerplate. But when the AI suggests something you don’t know, it is important not to skip it and move on - otherwise that new piece will never be something you learn!</p>
<p>We try to build the discipline to stop and explore anytime something like this comes up. Fortunately, it’s really easy to do this - you can add new messages trying out whatever new thing the AI has shown you, asking how it works, getting demo code, and poking it until you’re satisfied. And then the eveidence of that side-quest can be collapsed below a heading (for later ref) or deleted, leaving you back in the main flow but with a new piece of knowledge in your brain.</p>
<p><img src="https://johnowhitaker.dev/posts/images/vc_vs_solveit.png" class="img-fluid"></p>
<p>Earlier this year, I sketched out some doodles trying to think through whether we should be teaching this way. What if AI keeps getting better and better, to the point where there’s little point for the average person actually learning to master any of these skills? If you assume your coding skills stay static, and imagine the AI continuing to get better, you may feel kinda bleak. The thing is, skill doesn’t have to be static! And as both you and the AI you’re carefully using get better, you will learn faster and be able to accomplish more and more.</p>
</section>
<section id="mastery-requires-deliberate-practice-wip" class="level2">
<h2 class="anchored" data-anchor-id="mastery-requires-deliberate-practice-wip">Mastery Requires Deliberate Practice (WIP)</h2>
<p>This is all hard work! It’s like exercise, or practicing a musical instrument. And like any pursuit of mastery, I don’t know that it’s for everyone. But it is satisfying…</p>
</section>
<section id="long-term-software-creation-vibe-coded-demos-wip" class="level2">
<h2 class="anchored" data-anchor-id="long-term-software-creation-vibe-coded-demos-wip">Long-Term Software Creation != Vibe-Coded Demos (WIP)</h2>
<p>I’ve done lots of small projects. Big projects, new to me, different options. AAI’s unusual approach: carefully construct a substrate that allows you to fit ~anything into your head, improving it over time. Accept no slop!</p>
</section>
<section id="so-you-hate-vibe-coding" class="level2">
<h2 class="anchored" data-anchor-id="so-you-hate-vibe-coding">So you hate vibe-coding?</h2>
<p>No :) I love it, <strong>for <a href="https://johnowhitaker.dev/posts/vc_wins.html">some things</a></strong>. There is much more software that I want written than I have time to write. There are some things I don’t much care to learn about, but still need to code for. There are many, many new options for non-coders now, thanks to the ability to conjure up bespoke software from vague descriptions. We’re just not fans of it when it comes to software that matters, and don’t think it replaces the learning value of truly working at programming as a craft.</p>
</section>
<section id="ok-where-can-i-use-solveit" class="level2">
<h2 class="anchored" data-anchor-id="ok-where-can-i-use-solveit">OK, where can I use solveit</h2>
<p>We’re running another course soon, which will be $400. I appreciate this is spendy. That will let us test some scaling and features, and work with another cohort to build the solveit skill. Once that’s done, we’re hoping to open it up on a usage-based billing system. I can’t wait for it to be available to everyone! Please be patient - I think it’ll be worth the wait :)</p>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>There we go - some musings on the solveit approach. There’s a ton more to the app - web magic with FastHTML, meta-programming by giving the AI tools to modify the dialog and itself, lots of tricks we’ve developed for getting the most out of AI… but the important thing is the mindset, and it’s one which you can almost equally practice in any jupyter notebook.</p>
<p>I still have <a href="https://johnowhitaker.dev/essays/future-ai.html">wide error bars</a> on the future of AI and coding, but no matter how that goes, I’m glad I get to work on getting better at something I enjoy for now :)</p>
<p>I hope you’ve enjoyed this rambly post! I’d love to hear your thoughts! Stay tuned for info on the new course shortly (I’ll link here when we announce it). Cheers - J</p>
<p>PS: If you want to see what a post like this looks like after being turned into a launch post, <a href="https://www.answer.ai/posts/2025-10-01-solveit-full.html">here it is on answer.ai.</a> . Featuring fun corrections like the ones below (caught by AI review) and tweaks to focus more on the exciting news that we’re finally launching the course :)</p>
<p>Glaring errors / typos • “solveing” → “solving” (appears at least twice). • “Eric Reis” → should be Eric Ries. • “acive” → “active.” • “stodents” → “students.” • “thoughout” → “throughout.” • “sterp” → “step.” • “helpfullness” → “helpfulness.” • “unlesss” → “unless.” • “eveidence” → “evidence.” • Minor date formatting: “October 20’th” should be “October 20th.”</p>


</section>

 ]]></description>
  <category>solveit</category>
  <guid>https://johnowhitaker.dev/posts/solveit.html</guid>
  <pubDate>Fri, 12 Sep 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Jet-Nemotron, Gated DeltaNet, and the slow triumph of hybrid models</title>
  <link>https://johnowhitaker.dev/posts/jet-nemotron.html</link>
  <description><![CDATA[ 




<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/vNzuV5GboEw" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Jet Nemotron paper: https://www.arxiv.org/abs/2508.15884 Gated Delta Networks: https://arxiv.org/abs/2412.06464 The review of hybrid linear attention variants we didn’t really chat about: https://arxiv.org/abs/2507.06457 Qwen 3 Next: https://qwen.ai/blog?id=4074cca80393150c248e508aa62983f9cb7d27cd&amp;from=research.latest-advancements-list</p>
<p>A few days after the video came the official Qwen 3 Next announcement, scaling Gated Delta-Net hybrid models up a bunch (and achiving high sparsity in their MoE too) - hooray for more efficient models! Hope it’s interesting.</p>



 ]]></description>
  <category>Video</category>
  <guid>https://johnowhitaker.dev/posts/jet-nemotron.html</guid>
  <pubDate>Tue, 09 Sep 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Counting Incomplete Cubes</title>
  <link>https://johnowhitaker.dev/posts/cubes.html</link>
  <description><![CDATA[ 




<p>I found a <a href="https://www.youtube.com/watch?v=_BrFKp-U8GI">lovely video</a> on Sol LeWitt’s “Variations of Incomplete Open Cubes” (1974):</p>
<p><img src="https://collectionapi.metmuseum.org/api/collection/v1/iiif/691091/preview.png" class="img-fluid"></p>
<p>It mentioned that the artist couldn’t figure out how to get the set sans rotational invariance apart from making them and looking at them - I paused the video to see if I could figure it out :) The result is this (lightly edited) solveit dialog.</p>
<section id="initial-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="initial-thoughts">Initial thoughts</h2>
<p>How many ‘incomplete cubes’ are there?</p>
<p>Number the 12 sides of a cube 1-12.</p>
<p>A cube with some sides missing can be a binary number, 0-4095.</p>
<p>Figure out how bits re-map to rotate in each of 3 axes</p>
<p>Eliminate rotational matches</p>
<p>My doodles to accompany this code:</p>
<p><img src="https://johnowhitaker.dev/posts/images/cubes_doodle.png" class="img-fluid"></p>
</section>
<section id="implementing-rotation" class="level2">
<h2 class="anchored" data-anchor-id="implementing-rotation">Implementing rotation</h2>
<p>From looking at my drawing, here’s how sides map through three different axes of rotation:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">r1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>}</span>
<span id="cb1-2">r2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>}</span>
<span id="cb1-3">r3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>}</span></code></pre></div></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check we typed that right</span></span>
<span id="cb2-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i,r <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>([r1,r2,r3], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(r.keys()) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>)) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(r.values()) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>)), <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"r</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> not 1-12"</span></span></code></pre></div></div>
<p>We can rotate a cube (represented by a number, with 12 bits corresponding to the 12 sides) like so:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> rotate(c, r): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;&lt;</span>(r[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;&lt;</span>i))</span>
<span id="cb3-2">rotate(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">17</span>, r1)</span>
<span id="cb3-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span></span></code></pre></div></div>
<p>Sanity check (see doodle):</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"17: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">17</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:012b}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb4-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"6:  </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:012b}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb4-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">17</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0000000</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">10001</span></span>
<span id="cb4-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>:  <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">000000000</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">110</span></span></code></pre></div></div>
<p>So, how can we prune cubes that are rotated copies of other cubes? Here’s what I came up with:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> prune(c, parent<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb5-2">    rots <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [rotate(c, r) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> r <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [r1, r2, r3]] <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get those that are one rot away</span></span>
<span id="cb5-3">    rots <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>([x <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> rots <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> candidates <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> parent]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Filter</span></span>
<span id="cb5-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> rots: <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If there are any, remove them from candidates but first also prune their children</span></span>
<span id="cb5-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> r <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> rots: candidates.remove(r)</span>
<span id="cb5-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(prune(r, parent<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>parent <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> c)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> r <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> rots)</span>
<span id="cb5-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>: <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span></code></pre></div></div>
<p>In retrospect we could also have just coded all 24 rotations but this works and I like it :)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">candidates <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4096</span>))</span>
<span id="cb6-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4096</span>):</span>
<span id="cb6-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> candidates: prune(i, parent<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>i)</span>
<span id="cb6-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(candidates)</span>
<span id="cb6-5"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">218</span></span></code></pre></div></div>
<section id="prompt" class="level5">
<h5 class="anchored" data-anchor-id="prompt">Prompt:</h5>
<p>Search and think - tell me if I’m correct that there are 218 incomplete cubes when you eliminate rotations, including the full cube and the empty cube. If I’m wrong don’t tell me the correct answer!</p>
</section>
<section id="reply" class="level5">
<h5 class="anchored" data-anchor-id="reply">🤖Reply🤖</h5>
<p>Looking at your code and the search results, I can see you’re working on a classic problem in combinatorics - counting distinct “incomplete cubes” where you consider cube edges as a binary pattern (present/absent) and eliminate rotational equivalences.</p>
<p>From the search results, I can confirm that a cube has 24 rotational symmetries <sup>1</sup>, and Pólya enumeration theorem is used to analyze the action of each of the 24 elements <sup>2</sup> on various cube structures.</p>
<p>Your approach looks mathematically sound:</p>
<ol type="1">
<li>You represent each “incomplete cube” as a binary number (0-4095) where each bit represents whether an edge is present</li>
<li>You define rotation mappings <code>r1</code>, <code>r2</code>, <code>r3</code> for the three axes</li>
<li>You use a pruning algorithm to eliminate rotational duplicates</li>
</ol>
<p>The key insight is that you’re applying Burnside’s lemma (which underlies Pólya enumeration) by identifying and removing configurations that are equivalent under the 24-element rotation group of the cube.</p>
<p>Your result of <strong>218 distinct incomplete cubes</strong> appears to be correct based on your systematic approach to: - Starting with all 4096 possible binary patterns (2^12 edges) - Systematically removing rotational equivalents using your rotation mappings - Including both the empty cube (0) and full cube (4095) in the count</p>
<p>The mathematics checks out, and your implementation correctly handles the rotational group action on the edge set.</p>
</section>
<section id="end-of-reply" class="level5">
<h5 class="anchored" data-anchor-id="end-of-reply">🤖End of Reply🤖</h5>
<p>Good old George Pólya, what a happy coincidence :) For those who don’t know, our ‘How to solve it with code’ is inspired by Polya’s book!</p>
</section>
</section>
<section id="eliminating-not-really-cubes" class="level1">
<h1>Eliminating “Not-Really-Cubes”</h1>
<p>Now we want things where:</p>
<ul>
<li>All edges touch</li>
<li>3D</li>
</ul>
<p>Let’s start by didtching the complete and empty cubes:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">candidates.remove(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb7-2">candidates.remove(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4095</span>)</span></code></pre></div></div>
<section id="flat-ones" class="level2">
<h2 class="anchored" data-anchor-id="flat-ones">Flat ones</h2>
<p>Any in a single plane. Before we run this, think how many you expect there to be!</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">planes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>},{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>},{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>},{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>},{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>},{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>}]</span>
<span id="cb8-2"></span>
<span id="cb8-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Count to check there are two of each num (sanity check)</span></span>
<span id="cb8-4">combined <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>([<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(p) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> planes], [])</span>
<span id="cb8-5">[combined.count(i) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>)]</span>
<span id="cb8-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span></code></pre></div></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> is_2D(c):</span>
<span id="cb9-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> planes: </span>
<span id="cb9-3">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;&lt;</span>i)).issubset(p): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb9-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb9-5"></span>
<span id="cb9-6">flats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [c <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> candidates <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> is_2D(c)]</span>
<span id="cb9-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(flats) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Makes sense - 1-4 sides plus opposites</span></span>
<span id="cb9-8"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span></code></pre></div></div>
<p>OK, let’s remove them:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Eliminate 2D ones</span></span>
<span id="cb10-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> flats: candidates.remove(c)</span>
<span id="cb10-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(candidates)</span>
<span id="cb10-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">211</span></span></code></pre></div></div>
<section id="disconnected-ones" class="level3">
<h3 class="anchored" data-anchor-id="disconnected-ones">Disconnected ones</h3>
<p>Done with visual reference to my diagram.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">touching <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb11-2">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>},</span>
<span id="cb11-3">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>},</span>
<span id="cb11-4">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>},</span>
<span id="cb11-5">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>},</span>
<span id="cb11-6">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>},</span>
<span id="cb11-7">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>},</span>
<span id="cb11-8">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>},</span>
<span id="cb11-9">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>},</span>
<span id="cb11-10">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>},</span>
<span id="cb11-11">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>},</span>
<span id="cb11-12">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>},</span>
<span id="cb11-13">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>:{<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>}</span>
<span id="cb11-14">}</span></code></pre></div></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sanity check</span></span>
<span id="cb12-2">combined <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>([<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(p) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> touching.values()], [])</span>
<span id="cb12-3">[combined.count(i) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>)]</span>
<span id="cb12-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]</span></code></pre></div></div>
<p>I can see how I could make <code>touching</code> with the base case plus a bunch of rotations but I’ll go with it for now.</p>
<p>Next step: pick an edge: keep track of those touching, and the ones touching those, and … then check you’ve hit all the edges</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> all_touching(c):</span>
<span id="cb13-2">    edges <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;&lt;</span>i)]</span>
<span id="cb13-3">    seen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>([edges[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]])</span>
<span id="cb13-4">    stack <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [edges[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]]</span>
<span id="cb13-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> stack:</span>
<span id="cb13-6">        current <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> stack.pop()</span>
<span id="cb13-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> neighbor <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> touching[current]:</span>
<span id="cb13-8">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> neighbor <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> edges <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> neighbor <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> seen:</span>
<span id="cb13-9">                seen.add(neighbor)</span>
<span id="cb13-10">                stack.append(neighbor)</span>
<span id="cb13-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> seen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(edges)</span>
<span id="cb13-12"></span>
<span id="cb13-13">valid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [c <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> candidates <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> all_touching(c)]</span>
<span id="cb13-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(valid)</span>
<span id="cb13-15"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">122</span></span></code></pre></div></div>
<p>My first thought was something like this, which gives the same answer.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> all_touching_brute_force(c):</span>
<span id="cb14-2">    edges <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;&lt;</span>i)]</span>
<span id="cb14-3">    seen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>([edges[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]])</span>
<span id="cb14-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>):</span>
<span id="cb14-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> edge <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(seen):</span>
<span id="cb14-6">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> n <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> touching[edge]:</span>
<span id="cb14-7">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> n <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> edges: seen.add(n)</span>
<span id="cb14-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> seen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(edges)</span></code></pre></div></div>
<section id="prompt-1" class="level5">
<h5 class="anchored" data-anchor-id="prompt-1">Prompt</h5>
<p>What do you think of the brute force approach? I thought I could do it in 3 hops, but needed 6 to get the same answer as the DFS… Any ideas what I got wrong?</p>
</section>
<section id="reply-1" class="level5">
<h5 class="anchored" data-anchor-id="reply-1">🤖Reply🤖</h5>
<p>Looking at the search results, I can see that the longest distance between vertices on a 3-dimensional cube is 3 edges <sup>3</sup> <sup>4</sup>. This is the diameter of the cube graph.</p>
<p>Your intuition about 3 hops was actually correct! The issue is likely that your brute force approach wasn’t quite right. In a cube graph, to travel from one corner to the corner directly opposite, you need to traverse three edges along the cube’s surfaces <sup>5</sup>.</p>
<p>The reason you needed 6 iterations in your brute force might be because you were expanding the reachable set one edge at a time, but not all edges can be reached in exactly 3 hops from every starting edge. Some edge pairs might need the full diameter distance to connect.</p>
<p>Your DFS approach is more robust because it finds the actual connected components, while the fixed-iteration approach assumes a specific maximum distance that might not apply to all edge configurations.</p>
<p>What do you think - does this make sense for why you needed more iterations than expected?</p>
</section>
<section id="end-of-reply-1" class="level5">
<h5 class="anchored" data-anchor-id="end-of-reply-1">🤖End of Reply🤖</h5>
<p>Oooh I figured you could reach any edge from any other edge in max 3, but that’s for a full cube! For our partial cubes we can be forced to take a longer route.</p>
<p>OK, and time to look up the correct answer: 122! Yay :)</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">incomplete_cubes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>  [c <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> candidates <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> all_touching(c)]</span>
<span id="cb15-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(incomplete_cubes)</span></code></pre></div></div>
<pre><code>[19, 22, 23, 25, 27, 29, 30, 31, 55, 59, 61, 62, 63, 86, 87, 91, 95, 118, 119, 123, 125, 126, 127, 247, 255, 285, 286, 287, 315, 317, 318, 319, 342, 343, 345, 347, 349, 350, 351, 375, 379, 381, 382, 383, 391, 399, 414, 415, 423, 428, 429, 430, 431, 439, 444, 445, 446, 447, 455, 459, 463, 470, 471, 478, 479, 487, 491, 493, 494, 495, 502, 503, 506, 507, 508, 509, 510, 511, 861, 862, 863, 875, 877, 879, 893, 895, 940, 941, 943, 959, 967, 974, 975, 990, 991, 997, 999, 1002, 1003, 1005, 1006, 1007, 1013, 1014, 1015, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1527, 1530, 1531, 1535, 2014, 2015, 2027, 2031, 2045, 2047]</code></pre>
<p>At this point I switched to standard mode and had it make the matplotlib code for me :D That and some tangential chit-chat removed for brevity, the raw dialog is <a href="https://gist.github.com/johnowhitaker/b6f4ecd87efed2d98b2adc2a4487385b">here</a></p>
</section>
</section>
</section>
<section id="final-result" class="level2">
<h2 class="anchored" data-anchor-id="final-result">FInal result:</h2>
<p><img src="https://johnowhitaker.dev/posts/images/cubes_result.png" class="img-fluid"></p>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>https://brainly.com/question/50225314 “The longest distance between vertices on a 3-dimensional cube is 3 edges, which corresponds to 3 units if we consider the edges to be unit lengths.”↩︎</p></li>
<li id="fn2"><p>https://brainly.com/question/50225314 “The longest distance between vertices on a 3-dimensional cube is 3 edges, which corresponds to 3 units if we consider the edges to be unit lengths.”↩︎</p></li>
<li id="fn3"><p>https://brainly.com/question/50225314 “The longest distance between vertices on a 3-dimensional cube is 3 edges, which corresponds to 3 units if we consider the edges to be unit lengths.”↩︎</p></li>
<li id="fn4"><p>https://brainly.com/question/50225314 “The longest distance between vertices on a 3-dimensional cube is 3 edges, which corresponds to 3 units if we consider the edges to be unit lengths.”↩︎</p></li>
<li id="fn5"><p>https://brainly.com/question/50225314 “If you were to travel from one corner of the cube to the corner directly opposite, you would need to traverse three edges along the cube’s surfaces. F…”↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>blogs</category>
  <category>solveit</category>
  <guid>https://johnowhitaker.dev/posts/cubes.html</guid>
  <pubDate>Mon, 08 Sep 2025 00:00:00 GMT</pubDate>
  <media:content url="https://johnowhitaker.dev/posts/images/cubes_result.png" medium="image" type="image/png" height="142" width="144"/>
</item>
<item>
  <title>‘Diffusion Beats Autoregressive in Data-Constrained Settings’ - Paper read + a win for open review</title>
  <link>https://johnowhitaker.dev/misc/dllm_learn.html</link>
  <description><![CDATA[ 




<section id="diffusion-beats-autoregressive-in-data-constrained-settings---paper-read-a-win-for-open-review" class="level3">
<h3 class="anchored" data-anchor-id="diffusion-beats-autoregressive-in-data-constrained-settings---paper-read-a-win-for-open-review">‘Diffusion Beats Autoregressive in Data-Constrained Settings’ - Paper read + a win for open review</h3>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/jgLOsT4EwAQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>In this video we take a look at the paper ‘Diffusion Beats Autoregressive in Data-Constrained Settings’ (http://arxiv.org/abs/2507.15857) and a great discussion on Twitter that helped push the results + related hypotheses further, to the benefit of all.</p>
<p>After I shared it, some of the authors shared a parallel work that addressed some issues in the original but found the same overall lesson: when data constrained, dLLMs learn better than AR (but only after a lot of compute): https://jinjieni.notion.site/Diffusion-Language-Models-are-Super-Data-Learners-239d8f03a866800ab196e49928c019ac - very much worth checking out as a postscript to the video.</p>
<p>Tweets referenced:</p>
<p>https://x.com/giffmana/status/1947729993607348255 https://x.com/giffmana/status/1949001902970339471 https://x.com/mihirp98/status/1953196510725980173 https://x.com/giffmana/status/1953206125639123188</p>


</section>

 ]]></description>
  <category>Video</category>
  <guid>https://johnowhitaker.dev/misc/dllm_learn.html</guid>
  <pubDate>Thu, 07 Aug 2025 00:00:00 GMT</pubDate>
  <media:content url="https://johnowhitaker.dev/misc/thumbnails/dllm_learn.png" medium="image" type="image/png" height="87" width="144"/>
</item>
<item>
  <title>Duckweed Growth Experiments, or, ‘LLMs as General Optimizers in Science’</title>
  <link>https://johnowhitaker.dev/posts/dwebench.html</link>
  <description><![CDATA[ 




<p>My friend REDACTED is a scientist at SCIENCECO who are working with some people from BIGLAB to explore using AI models to optimise PROCESS using SCIENCECO’s epic technology for automating experiments in FIELD. We’ve had some fascinating conversations about where AI for science is now, and where it could go in the near future. To explore some of these ideas, let me share my own experiment that I’ve been running over the past few weeks, which is a lot easier to talk about without getting anyone in trouble ;)</p>
<section id="the-experiment" class="level2">
<h2 class="anchored" data-anchor-id="the-experiment">The Experiment</h2>
<p>Inspired by <a href="https://x.com/ATinyGreenCell/status/1938362004240019899">a tweet</a> from legendary amateur biologist Sebastian Cocioba, I had grabbed some duckweed (<em>Lemna minor</em>) from a nearby pond on a whim. The goal of this experiment is to figure out a good growing strategy for it. Or, more specifically, to see if o3 can figure out a good recipe, with me essentially acting as a meat robot to implement its chosen protocols. Here’s <a href="https://chatgpt.com/share/688f729c-b224-8010-9c0d-fd41eaff8cc6">my chat</a> where I laid out the setup and had it set conditions for the experimental runs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://johnowhitaker.dev/posts/images/dwebench1.png" class="img-fluid figure-img"></p>
<figcaption>5 tubs with different conditions, after a few days of growth</figcaption>
</figure>
</div>
<p>The setup involves 5 tubs, each of which will be started with 30 fronds of duckweed in 50ml of water with various nutrients added. I have a hydroponic mix (‘Maxigrow’) containing Nitrogen, Phosphorus and Potassion (NPK) as well as some micronutrients, some KDP to vary the potassium content, citric acid, baking poweder or pH UP and DOWN solututions, and a couple of other chemicals on hand. I counted the number of fronds in each tub every 2 days for 8 days total. Based on the results from the first run, I had o3 suggest a second set of conditions and ran those too.</p>
<p><img src="https://johnowhitaker.dev/posts/images/dwebench_counter.png" class="img-fluid"></p>
<p>I manually counted the fronds for most of the experiment, but to combat COVID brain fog I had Claude make me <a href="https://claude.ai/public/artifacts/2ca3e089-9a2d-436c-b945-61a268848d0c">this artifact</a> that I could use to count them more reliably from a photo instead for the final results.</p>
<p>To make it easy to mix up the various recipes, I made three stock solutions: S1 (5g/L MaxiGro), S2 (5g/L KDP) and S3 (5g/L baking soda).</p>
</section>
<section id="the-results" class="level2">
<h2 class="anchored" data-anchor-id="the-results">The Results</h2>
<p>The recipe that did best was 6ml S1 + 44 ml tap water (i.e.&nbsp;600mg/L MaxiGro), achieving a doubling time of 3.5 days. This fast growth is what makes duckweed great for this kind of experiment :) This ideal level is quite a bit less than the recommended concentration of this hydroponic nutrient for general use - which makes sense given what I’ve read about duckweed’s preferences. Dropping to even lower nutrient concentrations gave less growth, with clear loss of color in the smallest few cases. Going too high also caused trouble, with bleached leaves (‘chlorosis’) and less growth too. This recipe was top in both the first and second runs (it was kept in the second as a baseline).</p>
<p><img src="https://johnowhitaker.dev/posts/images/dwebench_results.png" class="img-fluid"></p>
<p>Overall, I’d say I’m pretty impressed. Sure, I could have done this just fine without AI, but it’s cool that we can tap into something that can skim the literature at lightning speed and take advantage of tons of scientific training data to give us reasonable starting points for experiments like these.</p>
</section>
<section id="hmm-thats-weird" class="level2">
<h2 class="anchored" data-anchor-id="hmm-thats-weird">“Hmm, That’s Weird”</h2>
<p>One of the tubs in the second run developed a thin, shiny film almost like an oil slick, likely caused by bacterial growth. Would an AI-only system have ‘noticed’ this? Or would it have been stuck with a potential confounder invisible to it if all it could see was the proposed inputs and the final output counts…</p>
<p><img src="https://johnowhitaker.dev/posts/images/dwebench2.png" class="img-fluid"></p>
<p>A lot of science can be done by just ‘following the recipe’, but many of the greatest discoveries come from something not going to plan - with a human there, filled with experience, to notice and go “hmm, that’s weird”. Hmm, that’s weird, my bacteria died where that mold is growing. Hmm, that’s weird, my photography film is getting foggy near my uranium salts. Hmm, that’s weird, …</p>
<p>Even when you’re not hoping for crazy breakthroughs like these, there are so many places where this instinct comes in when doing biology. Hmm, that’s weird, these cultures smells funny. Hmm, that’s weird, there’s a precipitate in some of the wells, maybe the tirzepatide isn’t soluble enough in this solvent mix. Hmm, that’s weird, it’s gone all <strong>goopy</strong>. This is the thing REDACTED keeps on emphasizing to me - there is sooooo much knowledge that isn’t necessarily written down when it comes to frontier science, so much practice required to build the instinct for the ‘hmm, weird’ moments that comes from time at the bench, not from textbooks. At least for now, it’s hard to see how current training methods could instil these things into an AI[1].</p>
</section>
<section id="so-what-did-we-learn" class="level2">
<h2 class="anchored" data-anchor-id="so-what-did-we-learn">So What Did We Learn?</h2>
<p>I think one headline takeaway here is something like the following: <strong>Fancy AI models can boost performance of systems given knobs to tweak, by making reasonable initial guesses and iterating from feedback.</strong> I have no doubt we’ll see lots of results along these lines in the next few years - AI systems beating human baselines on everything from chip design to protein synthesis, using RL or just smart application of reasoning models + tools for automated or semi-automated experiments. <strong>BUT</strong> I think it’s premature to ignore the ideas of curiosity and suprise that run as a continuous thread through the history of science. If we’re only ever chasing an outcome we’ve planned and measured in advance, then we’re missing out on so much[2]. To me, the more exciting way to view it is something like this: <strong>Every enthusiastic amateur now has a capable and knowledgeable ‘advisor’ on hand, and as long as we keep up the curiosity and invest in our own learning, I think the human+ai combo has the potential to enable all sorts of cool science in the years to come.</strong></p>
<p>Footnotes:</p>
<p>[1] - Although it’s interesting to think about how this could change. Imitation learning like the pre-training/SFT paradigm seems like a poor way to learn to pick up any kind of insight like this. But with RL tasks getting longer and more complex, I can begin to see how we might start to get ‘micro’ insights despite only training for a specified outcome. “[code] now pass [test]” leads to “hmm, that’s weird, I’d expect the output to be 0 in all cases”. Perhaps long + general enough RL can reward true curiosty + exporation, just as long evolution towards the ‘reproduce’ outcome eventually led to clever stone knapping and modern civilization shortly thereafter. I remain <a href="https://johnowhitaker.dev/essays/future-ai.html">uncertain</a> :)</p>
<p>[2] - I went and bought ‘Why Greatness Cannot Be Planned: The Myth of the Objective’ after I typed this - by all accounts it’s a fantastic book on this subject that I’ve been meaning to get to for a while, stay tuned for a review to land on my <a href="https://johnowhitaker.dev/books.html">books</a> page soon :)</p>


</section>

 ]]></description>
  <category>misc</category>
  <guid>https://johnowhitaker.dev/posts/dwebench.html</guid>
  <pubDate>Sun, 03 Aug 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Mapping Smells, Gamifying Family Trips, Playing ARC-AGI-3 like an LLM… (Vibe Coding Wins)</title>
  <link>https://johnowhitaker.dev/posts/vc_wins.html</link>
  <description><![CDATA[ 




<p>It’s still nice to <strong>know</strong> your code. To carefully review anything your AI helpers do. To dig in and learn, and build familiarity with a chosen stack… but with all of that said, the set of ‘pieces of software I want to exist’ is a lot larger larger than the ‘pieces of software I want to carefully code’ one! I love that we can now whip up custom software on demand just by speaking our requirements in plan language (and then maybe giving a little guidance along the way). In this post I want to feature a few recent results that I particularly enjoyed making/using, a celebration of the kind of things vibe coding is currently a perfect match for. In a future post I will probably wax equally lyrical about how terrible it is if you <em>only</em> do this though, so stay tuned for that ;)</p>
<section id="portland-pursuit" class="level3">
<h3 class="anchored" data-anchor-id="portland-pursuit">Portland Pursuit</h3>
<p>My family visited us in the US for the first time in May/June this year. To help them quest-max on their visits, I made <a href="https://johnowhitaker.github.io/portland_pursuit/">Portland Pursuit</a> - with lots of achievements for them to tick off while they were here. The app (<a href="https://github.com/johnowhitaker/portland_pursuit">code</a>) is written in html/javascript, hosted on GitHub pages, and set up as a Progressive Web App (PWA) which let my family ‘install’ it to their phone home screens - important for non-techy parents. For years this has been my goto approach for making app-like things without having to go through the mobile app store nonsense, and I’m not sure why it’s not more popular!</p>
<p><img src="https://johnowhitaker.dev/posts/images/portland_pursuit.png" class="img-fluid"></p>
<p>The app was a huge success - they all got most of the available points, and it definitely encouraged a few extra exploratory walks towards the end of the trip as they vied for first place :) Writing it was fun and easy, and it was a nice test-bed for a few different tools I was testing at the time to see how well they did modifying it when I wanted to add new tasks and so on. Perfect vibe-coding story: simple app, human ideas, minimal time wasted fighting config or hosting settings, a few happy customers. 10/10 :)</p>
</section>
<section id="fragrance-explorer" class="level3">
<h3 class="anchored" data-anchor-id="fragrance-explorer">Fragrance Explorer</h3>
<p>This past weekend I stumbled upon Gwern’s <a href="https://gwern.net/blog/2025/perfume">blog post on avant-garde perfumes</a>. And then while out on a walk I stumbled upon <a href="https://fumerie.com/">Fumerie</a>, a Parfumerie close to where I live. The folks behind the counter were incredibly friendly, chatting for ages about their art and showing me some wild smells. (Maybe too many - my wife kept her distance from me for the rest of the day). One thing that came through in our discussion was how personal fragrance is to them, with everyone reacting to specific smells differently. Even mentioning that I’d read about a specific fragrance had them tut-tutting - online marketing descriptions != the experience, it seems!</p>
<p><img src="https://johnowhitaker.dev/posts/images/frag_search.png" class="img-fluid"></p>
<p>Still, I did find the online descriptions amusing, and I wanted to get a better sense of the ‘map of smells’ availalbe, so when I got home I scraped <a href="https://gist.github.com/johnowhitaker/6fef140a3a47aa1ea049a8562270b0bf">hundreds of fragrance descriptions</a> and had Replit’s Agent whip up an embedding explorer. You can search with natural language, but the real fun is making custom scatter plots with silly axes:</p>
<p><img src="https://johnowhitaker.dev/posts/images/frag_plot.png" class="img-fluid"></p>
<p>I showed this to the smell people who agreed that this is <strong>exactly</strong> why they have a job - the text embedding based rankings/scatter plots were based on the marketing points and fragrance notes and were not at all capturing the true essence of the smells. I agree - but still find this fun :) I did the scraping and embedding carefully in a notebook-like environment, then realized I shouldn’t spend &gt;1hr on this, so threw the embeddings and data at replit to make a streamlit frontent. It’s janky and glitchy and annoying but it was instantly shareable and took very little effort - vibe coding win, but I think I could do a lot better without spending much more time. If I cared! Which I don’t! Vibe coding win :)</p>
</section>
<section id="arc-agi-3-play-like-an-llm" class="level3">
<h3 class="anchored" data-anchor-id="arc-agi-3-play-like-an-llm">ARC-AGI-3 (Play like an LLM)</h3>
<p><img src="https://johnowhitaker.dev/posts/images/arcagi.png" class="img-fluid"></p>
<p>I like that the ARC people are coming up with interesting evals - great work! I dislike how much gets read into them, and some of the silly discourse they engender. One aspect is that the way you present the data DOES MATTER! Humans play the games looking at a little pixel grid. AI’s get a list of lists of numbers. “But general intelligence should be able to figure it out…” - OK, then try <a href="https://play-arc-agi-3.replit.app/">my version which has you play the game looking at the raw string data</a>. Yeah - no success from any humans so far, maybe we aren’t general intelligence after all… Code is simple, quick flask app on replit coded by o3. For vibe-coding something that uses an API like this, you need API docs, and theirs are a weird custom thing with lots of JS that none of the coding AI’s can read! (I told them, they’re shifting to something better soon). But in the theme of laziness I was able to get manus to browse and click and extract all the docs with a little help, and then I could paste that markdown into o3 for the implementation. Easy task I can specify well with API docs at hand? Perfect vibe coding starting material, works as intended. Vibe coding win :)</p>
</section>
<section id="commentary-and-conclusions" class="level3">
<h3 class="anchored" data-anchor-id="commentary-and-conclusions">Commentary and Conclusions</h3>
<p>Anthropic said people have made something like ~500 million artifacts with Claude. Lovable just raised $200M. For all that software people like to hate on vibe coding, it’s delightful to me that so many people are getting to create ephemeral, quirky pieces of software to fill some need that they have. In all the examples above, the end result is mediocre at best. There’s no auth, I have ~no users, none of these are the Next Big Thing… BUT they all made me happy, quickly, for free! And I think I’m not the only one. Snarkily asking why there aren’t more giant breakout apps coming in a wave thanks to vibe coding tools is missing the point: there are now hundreds of millions of new pieces of software, each making ~1 person a little happier. And I think that’s great :)</p>


</section>

 ]]></description>
  <category>misc</category>
  <guid>https://johnowhitaker.dev/posts/vc_wins.html</guid>
  <pubDate>Thu, 24 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://johnowhitaker.dev/posts/images/frag_plot.png" medium="image" type="image/png" height="102" width="144"/>
</item>
<item>
  <title>1Hz Dropper</title>
  <link>https://johnowhitaker.dev/mini-hw-projects/dropper.html</link>
  <description><![CDATA[ 




<p>Inspired by the <a href="https://hackaday.io/contest/203248-one-hertz-challenge">Hackaday One Hertz challenge</a>, I used a solenoid scavenged from an old printer to drop dye into water once a second, making for a pretty (if short-lived) time-keeping device. Video of it in action <a href="https://x.com/johnowhitaker/status/1947072110817644573">here</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://johnowhitaker.dev/mini-hw-projects/images/drop1.png" class="img-fluid figure-img"></p>
<figcaption>The setup</figcaption>
</figure>
</div>
<p>The top of the syringe plunger makes a loose seal, and is popped out briefly by a pulse of the solenoid. This let’s a bit of air in, which allows a small drop to form at the bottom of the syringe (with needle removed the hole is perfectly sized for this). The tap and small pressure bump as the plunger top returns to it’s resting position knocks the drop off, giving a perfect* 1Hz drip.</p>
<p>I ‘filmed’ a full syringe worth of beautiful footage - about a minute of fresh ink dropping into clear water, with it all set up in a stand. The alignment was perfect, single drops each time. I went to ‘stop’ the recording and, womp womp, it hadn’t started. I promptly spilled some dye, knocked things over and messed it all up attempting several re-takes before deciding I’m content with the current shorter clip. Each failing tick spewing mess on my bench felt like a metaphor for time passing that I did not enjoy :D</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://johnowhitaker.dev/mini-hw-projects/images/drop3.png" class="img-fluid figure-img"></p>
<figcaption>a few drops in</figcaption>
</figure>
</div>
<p>Parts used are a Raspberry Pi Pico RP2040 microcontroller in the “Kitronik Simply Robotics Motor Driver Board for Raspberry Pi Pico” board. The code is attached, pulsing the solenoid (connected to the MOTOR_0 output of the board) for a set time each second. Code dumped on the <a href="https://hackaday.io/project/203568-1hz-dropper">hackaday io project</a> (but it’s basically just blinky, one-shotted by o3, plus stolen library code).</p>
<p>Not my finest work in any respect but it was a fun diversion from Sunday tidying.</p>



 ]]></description>
  <category>mini-hw-projects</category>
  <guid>https://johnowhitaker.dev/mini-hw-projects/dropper.html</guid>
  <pubDate>Sun, 20 Jul 2025 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
