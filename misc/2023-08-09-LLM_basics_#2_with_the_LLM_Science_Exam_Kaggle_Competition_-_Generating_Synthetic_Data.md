---
title: "LLM basics #2 with the LLM Science Exam Kaggle Competition - Generating Synthetic Data"
date: 2023-08-09
categories: 
  - "Video"
image: "thumbnails/w4Js5My2KXw.jpg"
---

### LLM basics #2 with the LLM Science Exam Kaggle Competition - Generating Synthetic Data

{{< video https://www.youtube.com/embed/w4Js5My2KXw >}}

Another informal video as we work through the LLM Science Exam competition. Showing how you can - Start with a small dataset of high-quality examples- Train an LLM to generate more (Llama2 training with LoRA using PEFT and the TRL SFTTrainer example)- Filter the generated examples for quality- Train and repeat, building up a high-quality dataset in no time!I kept it more conceptual with a toy example here, but hopefully, you can see how this applies to the competition and to more serious applications. In a few weeks I'll be back from travelling and video quality should improve  -)Radek's dataset - https://www.kaggle.com/datasets/radek1/additional-train-data-for-llm-science-exam'Generate and train' notebook - https://colab.research.google.com/drive/1pXk9cbahwmtb0ultmnjGSmABjogYzDKtusp=sharingFor GPT3.5 function calling see the previous video - https://youtu.be/ddCYORu41XsTraining notebook (mostly just using the example script included with TRL) - https://colab.research.google.com/drive/1GxbUYZiLidteVX4qu5iSox6oxxEOHk5Ousp=sharing
